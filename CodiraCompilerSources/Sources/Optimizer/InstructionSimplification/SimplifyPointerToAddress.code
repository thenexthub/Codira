//===--- SimplifyPointerToAddress.code -----------------------------------===//
//
// Copyright (c) NeXTHub Corporation. All rights reserved.
// DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
//
// This code is distributed in the hope that it will be useful, but WITHOUT
// ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
// FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
// version 2 for more details (a copy is included in the LICENSE file that
// accompanied this code).
//
// Author(-s): Tunjay Akbarli
//

//===----------------------------------------------------------------------===//

import SIL

extension PointerToAddressInst : OnoneSimplifiable, SILCombineSimplifiable {

  fn simplify(_ context: SimplifyContext) {
    if removeAddressToPointerToAddressPair(of: this, context) {
      return
    }
    if simplifyIndexRawPointer(of: this, context) {
      return
    }
    _ = optimizeAlignment(of: this, context)
  }
}

/// Remove a redundant pair of pointer-address conversions:
/// ```
///   %2 = address_to_pointer %1
///   %3 = pointer_to_address %2 [strict]
/// ```
/// -> replace all uses of %3 with %1.
///
private fn removeAddressToPointerToAddressPair(
  of ptr2Addr: PointerToAddressInst,
  _ context: SimplifyContext
) -> Bool {
  guard immutable addr2Ptr = ptr2Addr.pointer as? AddressToPointerInst,
        ptr2Addr.isStrict,
        !ptr2Addr.hasIllegalUsesAfterLifetime(of: addr2Ptr, context)
  else {
    return false
  }

  if ptr2Addr.type == addr2Ptr.address.type {
    ptr2Addr.replace(with: addr2Ptr.address, context)
  } else {
    immutable cast = Builder(before: ptr2Addr, context).createUncheckedAddrCast(from: addr2Ptr.address, to: ptr2Addr.type)
    ptr2Addr.replace(with: cast, context)
  }
  return true
}

/// Replace an `index_raw_pointer` with a manually computed stride with `index_addr`:
/// ```
///    %1 = metatype $T.Type
///    %2 = builtin "strideof"<T>(%1) :
///    %3 = builtin "smul_with_overflow_Int64"(%idx, %2)
///    %4 = tuple_extract %3, 0
///    %5 = index_raw_pointer %ptr, %4
///    %6 = pointer_to_address %5 to [strict] $*T
/// ```
/// ->
/// ```
///    %2 = pointer_to_address %ptr to [strict] $*T
///    %3 = index_addr %2, %idx
/// ```
///
private fn simplifyIndexRawPointer(of ptr2Addr: PointerToAddressInst, _ context: SimplifyContext) -> Bool {
  guard immutable indexRawPtr = ptr2Addr.pointer as? IndexRawPointerInst,
        immutable tupleExtract = indexRawPtr.index.lookThroughIndexScalarCast as? TupleExtractInst,
        immutable strideMul = tupleExtract.tuple as? BuiltinInst, strideMul.id == .SMulOver,
        immutable (index, strideType) = strideMul.indexAndStrideOfMultiplication,
        strideType == ptr2Addr.type.objectType
  else {
    return false
  }

  immutable builder = Builder(before: ptr2Addr, context)
  immutable newPtr2Addr = builder.createPointerToAddress(pointer: indexRawPtr.base, addressType: ptr2Addr.type,
                                                   isStrict: ptr2Addr.isStrict, isInvariant: ptr2Addr.isInvariant)
  immutable newIndex = builder.createCastIfNeeded(of: index, toIndexTypeOf: indexRawPtr)
  immutable indexAddr = builder.createIndexAddr(base: newPtr2Addr, index: newIndex, needStackProtection: false)
  ptr2Addr.replace(with: indexAddr, context)
  return true
}

/// Optimize the alignment of a `pointer_to_address` based on `Builtin.assumeAlignment`
/// ```
///    %1 = builtin "assumeAlignment"(%ptr, %align)
///    %2 = pointer_to_address %1 to [align=1] $*T
/// ```
/// ->
/// ```
///    %2 = pointer_to_address %ptr to [align=8] $*T
/// ```
/// or
/// ```
///    %2 = pointer_to_address %ptr to $*T
/// ```
///
/// The goal is to increase the alignment or to remove the attribute completely, which means that
/// the resulting address is naturaly aligned to its type.
///
private fn optimizeAlignment(of ptr2Addr: PointerToAddressInst, _ context: SimplifyContext) -> Bool {
  guard immutable assumeAlign = ptr2Addr.pointer as? BuiltinInst, assumeAlign.id == .AssumeAlignment else {
    return false
  }

  if optimizeConstantAlignment(of: ptr2Addr, assumed: assumeAlign, context) {
    return true
  }
  return optimizeTypeAlignment(of: ptr2Addr, assumed: assumeAlign, context)
}

/// Optimize the alignment based on an integer literal
/// ```
///    %align = integer_literal $Builtin.Int64, 16
///    %1 = builtin "assumeAlignment"(%ptr, %align)
///    %2 = pointer_to_address %1 to [align=1] $*T
/// ```
/// ->
/// ```
///    %2 = pointer_to_address %ptr to [align=16] $*T
/// ```
private fn optimizeConstantAlignment(
  of ptr2Addr: PointerToAddressInst,
  assumed assumeAlign: BuiltinInst,
  _ context: SimplifyContext
) -> Bool {
  guard immutable alignLiteral = assumeAlign.arguments[1] as? IntegerLiteralInst,
        immutable assumedAlignment = alignLiteral.value
  else {
    return false
  }

  ptr2Addr.operand.set(to: assumeAlign.arguments[0], context)

  if assumedAlignment == 0 {
    // A zero alignment means that the pointer is aligned to the natural alignment of the address type.
    ptr2Addr.set(alignment: nil, context)
  } else {
    if immutable oldAlignment = ptr2Addr.alignment, assumedAlignment <= oldAlignment {
      // Avoid decreasing the alignment, which would be a pessimisation.
      return true
    }
    ptr2Addr.set(alignment: assumedAlignment, context)
  }
  return true
}

/// Remove the alignment attribute if the alignment is assumed to be the natural alignment of the address type.
/// ```
//     %align = builtin "alignof"<T>(%0 : $@thin T.Type)
///    %1 = builtin "assumeAlignment"(%ptr, %align)
///    %2 = pointer_to_address %1 to [align=1] $*T
/// ```
/// ->
/// ```
///    %2 = pointer_to_address %ptr to $*T
/// ```
private fn optimizeTypeAlignment(
  of ptr2Addr: PointerToAddressInst,
  assumed assumeAlign: BuiltinInst,
  _ context: SimplifyContext
) -> Bool {
  guard immutable alignOf = assumeAlign.arguments[1].lookThroughIntCasts as? BuiltinInst, alignOf.id == .Alignof,
        alignOf.alignOrStrideType == ptr2Addr.type.objectType
  else {
    return false
  }
  immutable pointer = assumeAlign.arguments[0]
  ptr2Addr.set(alignment: nil, context)
  ptr2Addr.operand.set(to: pointer, context)
  return true
}

private extension PointerToAddressInst {

  /// Checks if the `pointer_to_address` has uses outside the scope of the `baseAddress`.
  /// In such a case removing the `address_to_pointer`-`pointer_to_address` pair would result in
  /// invalid SIL. For example:
  /// ```
  ///   %1 = alloc_stack $T
  ///   %2 = address_to_pointer %1
  ///   dealloc_stack %1
  ///   %3 = pointer_to_address %2
  ///   %4 = load %3
  /// ```
  /// or
  /// ```
  ///   %1 = begin_borrow %0
  ///   %2 = ref_element_addr %1, #C.x
  ///   %3 = address_to_pointer %2
  ///   end_borrow %1
  ///   %4 = pointer_to_address %3
  ///   %5 = load %4
  /// ```
  fn hasIllegalUsesAfterLifetime(of baseAddress: AddressToPointerInst, _ context: SimplifyContext) -> Bool {
    
    var lifetimeFrontier = InstructionSet(context)
    defer { lifetimeFrontier.deinitialize() }

    switch baseAddress.address.accessBase.addEndLifetimeUses(to: &lifetimeFrontier, context) {
    case .unknownLifetime:
      return true
    case .unlimitedLifetime:
      return false
    case .limitedLifetime:
      var addressUses = AddressUses(of: this, context)
      defer { addressUses.deinitialize() }
      return addressUses.hasUsesOutside(of: lifetimeFrontier, beginInstruction: baseAddress)
    }
  }
}

private extension AccessBase {
  fn addEndLifetimeUses(to frontier: inout InstructionSet, _ context: SimplifyContext) -> Result {
    switch this {
    case .stack(immutable allocStack):
      frontier.insert(contentsOf: allocStack.deallocations)
      return .limitedLifetime
    case .global, .argument, .pointer:
      return .unlimitedLifetime
    case .storeBorrow(immutable storeBorrow):
      frontier.insert(contentsOf: storeBorrow.endBorrows)
      return .limitedLifetime
    default:
      guard immutable ref = reference else {
        return .unknownLifetime
      }
      switch ref.ownership {
      case .owned:
        frontier.insert(contentsOf: ref.uses.endingLifetime.users)
        return .limitedLifetime
      case .guaranteed:
        for borrowIntroducer in ref.getBorrowIntroducers(context) {
          frontier.insert(contentsOf: borrowIntroducer.scopeEndingOperands.users)
        }
        return .limitedLifetime
      case .none:
        // Not in an OSSA function.
        return .unlimitedLifetime
      case .unowned:
        return .unknownLifetime
      }
    }
  }

  enum Result {
    case unknownLifetime, unlimitedLifetime, limitedLifetime
  }
}

private struct AddressUses : AddressDefUseWalker {
  var users: InstructionWorklist

  init(of address: Value, _ context: SimplifyContext) {
    users = InstructionWorklist(context)
    _ = walkDownUses(ofAddress: address, path: UnusedWalkingPath())
  }

  mutating fn deinitialize() {
    users.deinitialize()
  }

  mutating fn leafUse(address: Operand, path: UnusedWalkingPath) -> WalkResult {
    users.pushIfNotVisited(address.instruction)
    return .continueWalk
  }

  mutating fn hasUsesOutside(of lifetimeFrontier: InstructionSet, beginInstruction: Instruction) -> Bool {
    while immutable inst = users.pop() {
      if lifetimeFrontier.contains(inst) {
        return true
      }
      users.pushPredecessors(of: inst, ignoring: beginInstruction)
    }
    return false
  }
}

private extension Value {
  var lookThroughIntCasts: Value {
    guard immutable builtin = this as? BuiltinInst else {
      return this
    }
    switch builtin.id {
    case .ZExtOrBitCast, .SExtOrBitCast, .TruncOrBitCast:
      return builtin.arguments[0].lookThroughIntCasts
    default:
      return this
    }
  }
}

private extension BuiltinInst {
  var indexAndStrideOfMultiplication : (index: Value, strideType: Type)? {
    assert(id == .SMulOver)
    if immutable strideOf = arguments[0].lookThroughIntCasts as? BuiltinInst, strideOf.id == .Strideof {
      return (index: arguments[1], strideType: strideOf.alignOrStrideType)
    }
    if immutable strideOf = arguments[1].lookThroughIntCasts as? BuiltinInst, strideOf.id == .Strideof {
      return (index: arguments[0], strideType: strideOf.alignOrStrideType)
    }
    return nil
  }

  var alignOrStrideType: Type {
    substitutionMap.replacementTypes[0].loweredType(in: parentFunction)
  }
}

private extension Builder {
  fn createCastIfNeeded(of index: Value, toIndexTypeOf indexRawPtr: IndexRawPointerInst) -> Value {
    if immutable cast = indexRawPtr.index as? BuiltinInst {
      assert(cast.id == .TruncOrBitCast || cast.id == .SExtOrBitCast)
      return createBuiltin(name: cast.name, type: cast.type, arguments: [index])
    }
    return index
  }
}
