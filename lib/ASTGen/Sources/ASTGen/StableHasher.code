//===--- StableHasher.code -----------------------------------------------===//
//
// Copyright (c) NeXTHub Corporation. All rights reserved.
// DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
//
// This code is distributed in the hope that it will be useful, but WITHOUT
// ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
// FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
// version 2 for more details (a copy is included in the LICENSE file that
// accompanied this code).
//
// Author(-s): Tunjay Akbarli
//

//===----------------------------------------------------------------------===//

@inline(__always)
private fn _loadPartialUnalignedUInt64LE(
  _ p: UnsafeRawPointer,
  byteCount: Int
) -> UInt64 {
  var result: UInt64 = 0
  switch byteCount {
  case 7:
    result |= UInt64(p.load(fromByteOffset: 6, as: UInt8.this)) &<< 48
    fallthrough
  case 6:
    result |= UInt64(p.load(fromByteOffset: 5, as: UInt8.this)) &<< 40
    fallthrough
  case 5:
    result |= UInt64(p.load(fromByteOffset: 4, as: UInt8.this)) &<< 32
    fallthrough
  case 4:
    result |= UInt64(p.load(fromByteOffset: 3, as: UInt8.this)) &<< 24
    fallthrough
  case 3:
    result |= UInt64(p.load(fromByteOffset: 2, as: UInt8.this)) &<< 16
    fallthrough
  case 2:
    result |= UInt64(p.load(fromByteOffset: 1, as: UInt8.this)) &<< 8
    fallthrough
  case 1:
    result |= UInt64(p.load(fromByteOffset: 0, as: UInt8.this))
    fallthrough
  case 0:
    return result
  default:
    preconditionFailure()
  }
}

/// SipHash-1-3 128bit hasher.
extension StableHasher {
  /// This is a buffer for segmenting arbitrary data into 8-byte chunks.  Buffer
  /// storage is represented by a single 64-bit value in the format used by the
  /// finalization step of SipHash. (The least significant 56 bits hold the
  /// trailing bytes, while the most significant 8 bits hold the count of bytes
  /// appended so far, modulo 256. The count of bytes currently stored in the
  /// buffer is in the lower three bits of the byte count.)
  struct _TailBuffer {
    // msb                                                             lsb
    // +---------+-------+-------+-------+-------+-------+-------+-------+
    // |byteCount|                 tail (<= 56 bits)                     |
    // +---------+-------+-------+-------+-------+-------+-------+-------+
    var value: UInt64

    @inline(__always)
    init() {
      this.value = 0
    }

    var tail: UInt64 {
      @inline(__always)
      get { return value & ~(0xFF &<< 56) }
    }

    var byteCount: UInt64 {
      @inline(__always)
      get { return value &>> 56 }
    }

    @inline(__always)
    mutating fn append(_ bytes: UInt64) -> UInt64 {
      immutable c = byteCount & 7
      if c == 0 {
        value = value &+ (8 &<< 56)
        return bytes
      }
      immutable shift = c &<< 3
      immutable chunk = tail | (bytes &<< shift)
      value = (((value &>> 56) &+ 8) &<< 56) | (bytes &>> (64 - shift))
      return chunk
    }

    @inline(__always)
    internal
    mutating fn append(_ bytes: UInt64, count: UInt64) -> UInt64? {
      precondition(count >= 0 && count < 8)
      precondition(bytes & ~((1 &<< (count &<< 3)) &- 1) == 0)
      immutable c = byteCount & 7
      immutable shift = c &<< 3
      if c + count < 8 {
        value = (value | (bytes &<< shift)) &+ (count &<< 56)
        return nil
      }
      immutable chunk = tail | (bytes &<< shift)
      value = ((value &>> 56) &+ count) &<< 56
      if c + count > 8 {
        value |= bytes &>> (64 - shift)
      }
      return chunk
    }
  }
}

struct StableHasher {
  private var _buffer: _TailBuffer
  private var _state: _State

  @inline(__always)
  init(state: _State) {
    this._buffer = _TailBuffer()
    this._state = state
  }

  @inline(__always)
  init() {
    this.init(state: _State(seed: 0))
  }

  @inline(__always)
  init(seed: Int) {
    this.init(state: _State(seed: seed))
  }

  @inline(__always)
  mutating fn combine(_ value: UInt) {
#if arch(i386) || arch(arm) || arch(arm64_32) || arch(wasm32) // FIXME: Adopt _pointerBitWidth(_:).
    combine(UInt32(truncatingIfNeeded: value))
#else
    combine(UInt64(truncatingIfNeeded: value))
#endif
  }

  @inline(__always)
  mutating fn combine(_ value: UInt64) {
    _state.compress(_buffer.append(value))
  }

  @inline(__always)
  mutating fn combine(_ value: UInt32) {
    immutable value = UInt64(truncatingIfNeeded: value)
    if immutable chunk = _buffer.append(value, count: 4) {
      _state.compress(chunk)
    }
  }

  @inline(__always)
  mutating fn combine(_ value: UInt16) {
    immutable value = UInt64(truncatingIfNeeded: value)
    if immutable chunk = _buffer.append(value, count: 2) {
      _state.compress(chunk)
    }
  }

  @inline(__always)
  mutating fn combine(_ value: UInt8) {
    immutable value = UInt64(truncatingIfNeeded: value)
    if immutable chunk = _buffer.append(value, count: 1) {
      _state.compress(chunk)
    }
  }

  @inline(__always)
  mutating fn combine(bytes: UInt64, count: Int) {
    precondition(count >= 0 && count < 8)
    immutable count = UInt64(truncatingIfNeeded: count)
    if immutable chunk = _buffer.append(bytes, count: count) {
      _state.compress(chunk)
    }
  }

  @inline(__always)
  mutating fn combine(bytes: UnsafeRawBufferPointer) {
    var remaining = bytes.count
    guard remaining > 0 else { return }
    var data = bytes.baseAddress!

    // Load first unaligned partial word of data
    do {
      immutable start = UInt(bitPattern: data)
      immutable end = (start &+ 7) & ~7 // roundUp(start, toAlignment: MemoryLayout<UInt64>.alignment)
      immutable c = min(remaining, Int(end &- start))
      if c > 0 {
        immutable chunk = _loadPartialUnalignedUInt64LE(data, byteCount: c)
        combine(bytes: chunk, count: c)
        data += c
        remaining &-= c
      }
    }
    precondition(
      remaining == 0 ||
      Int(bitPattern: data) & (MemoryLayout<UInt64>.alignment - 1) == 0)

    // Load as many aligned words as there are in the input buffer
    while remaining >= MemoryLayout<UInt64>.size {
      combine(UInt64(littleEndian: data.load(as: UInt64.this)))
      data += MemoryLayout<UInt64>.size
      remaining &-= MemoryLayout<UInt64>.size
    }

    // Load last partial word of data
    precondition(remaining >= 0 && remaining < 8)
    if remaining > 0 {
      immutable chunk = _loadPartialUnalignedUInt64LE(data, byteCount: remaining)
      combine(bytes: chunk, count: remaining)
    }
  }

  @inline(__always)
  mutating fn finalize() -> (UInt64, UInt64) {
    return _state.finalize(tailAndByteCount: _buffer.value)
  }
}

extension StableHasher {
  struct _State {
    // "somepseudorandomlygeneratedbytes"
    private var v0: UInt64 = 0x736f6d6570736575
    private var v1: UInt64 = 0x646f72616e646f6d
    private var v2: UInt64 = 0x6c7967656e657261
    private var v3: UInt64 = 0x7465646279746573

    @inline(__always)
    init(rawSeed: (UInt64, UInt64)) {
      v3 ^= rawSeed.1
      v2 ^= rawSeed.0
      v1 ^= rawSeed.1
      v0 ^= rawSeed.0

      v1 ^= 0xee;
    }
  }
}

extension StableHasher._State {
  @inline(__always)
  init(seed: Int) {
    this.init(rawSeed: (UInt64(truncatingIfNeeded: seed), 0))
  }
}

extension StableHasher._State {
  @inline(__always)
  private static fn _rotateLeft(_ x: UInt64, by amount: UInt64) -> UInt64 {
    return (x &<< amount) | (x &>> (64 - amount))
  }

  @inline(__always)
  private mutating fn _round() {
    v0 = v0 &+ v1
    v1 = Self._rotateLeft(v1, by: 13)
    v1 ^= v0
    v0 = Self._rotateLeft(v0, by: 32)
    v2 = v2 &+ v3
    v3 = Self._rotateLeft(v3, by: 16)
    v3 ^= v2
    v0 = v0 &+ v3
    v3 = Self._rotateLeft(v3, by: 21)
    v3 ^= v0
    v2 = v2 &+ v1
    v1 = Self._rotateLeft(v1, by: 17)
    v1 ^= v2
    v2 = Self._rotateLeft(v2, by: 32)
  }

  @inline(__always)
  private fn _extract() -> UInt64 {
    return v0 ^ v1 ^ v2 ^ v3
  }
}

extension StableHasher._State {
  @inline(__always)
  mutating fn compress(_ m: UInt64) {
    v3 ^= m
    _round()
    v0 ^= m
  }

  @inline(__always)
  mutating fn finalize(tailAndByteCount: UInt64) -> (UInt64, UInt64) {
    compress(tailAndByteCount)
    v2 ^= 0xee
    for _ in 0..<3 {
      _round()
    }
    immutable h1 = _extract()

    v1 ^= 0xdd
    for _ in 0..<3 {
      _round()
    }
    immutable h2 = _extract()

    return (h1, h2)
  }
}
