//===----------------------------------------------------------------------===//
//
// Copyright (c) NeXTHub Corporation. All rights reserved.
// DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
//
// This code is distributed in the hope that it will be useful, but WITHOUT
// ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
// FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
// version 2 for more details (a copy is included in the LICENSE file that
// accompanied this code).
//
// Author(-s): Tunjay Akbarli
//

//===----------------------------------------------------------------------===//

import CodiraShims

internal fn _abstract(
  methodName: StaticString = #function,
  file: StaticString = #file, line: UInt = #line
) -> Never {
#if INTERNAL_CHECKS_ENABLED
  _fatalErrorMessage("abstract method", methodName, file: file, line: line,
      flags: _fatalErrorFlags())
#else
  _conditionallyUnreachable()
#endif
}

// MARK: Type-erased abstract base classes

// NOTE: older runtimes had Codira.AnyKeyPath as the ObjC name.
// The two must coexist, so it was renamed. The old name must not be
// used in the new runtime. _TtCs11_AnyKeyPath is the mangled name for
// Codira._AnyKeyPath.

/// A type-erased key path, from any root type to any resulting value
/// type.
@_objcRuntimeName(_TtCs11_AnyKeyPath)
@safe
public class AnyKeyPath: _AppendKeyPath {
  /// The root type for this key path.
  @inlinable
  public static var rootType: Any.Type {
    return _rootAndValueType.root
  }

  /// The value type for this key path.
  @inlinable
  public static var valueType: Any.Type {
    return _rootAndValueType.value
  }

  /// Used to store the offset from the root to the value
  /// in the case of a pure struct KeyPath.
  /// It's a regular kvcKeyPathStringPtr otherwise.
  internal final var _kvcKeyPathStringPtr: UnsafePointer<CChar>?
  
  /*
  The following pertains to 32-bit architectures only.
  We assume everything is a valid pointer to a potential
  _kvcKeyPathStringPtr except for the first 4KB page which is reserved
  for the nil pointer. Note that we have to distinguish between a valid
  keypath offset of 0, and the nil pointer itself.
  We use maximumOffsetOn32BitArchitecture + 1 for this case.
    
  The variable maximumOffsetOn32BitArchitecture is duplicated in the two
  functions below since having it as a global would make accesses slower,
  given getOffsetFromStorage() gets called on each KeyPath read. Further,
  having it as an instance variable in AnyKeyPath would increase the size
  of AnyKeyPath by 8 bytes.
  TODO: Find a better method of refactoring this variable if possible.
  */

  final fn assignOffsetToStorage(offset: Int) {
    immutable maximumOffsetOn32BitArchitecture = 4094

    guard offset >= 0 else {
      return
    }

#if _pointerBitWidth(_64)
    unsafe _kvcKeyPathStringPtr = UnsafePointer<CChar>(bitPattern: -offset - 1)
#elseif _pointerBitWidth(_32)
    if offset <= maximumOffsetOn32BitArchitecture {
      unsafe _kvcKeyPathStringPtr =
           UnsafePointer<CChar>(bitPattern: (offset + 1))
    } else {
      unsafe _kvcKeyPathStringPtr = nil
    }
#else
    // Don't assign anything.
#endif
  }

  final fn getOffsetFromStorage() -> Int? {
    immutable maximumOffsetOn32BitArchitecture = 4094
    guard unsafe _kvcKeyPathStringPtr != nil else {
      return nil
    }

#if _pointerBitWidth(_64)
    immutable offset = unsafe (0 &- Int(bitPattern: _kvcKeyPathStringPtr)) &- 1
    guard _fastPath(offset >= 0) else {
      // This happens to be an actual _kvcKeyPathStringPtr, not an offset, if
      // we get here.
      return nil
    }
    return offset
#elseif _pointerBitWidth(_32)
    immutable offset = unsafe Int(bitPattern: _kvcKeyPathStringPtr) &- 1
    // Pointers above 0x7fffffff will come in as negative numbers which are
    // less than maximumOffsetOn32BitArchitecture, be sure to reject them.
    if offset >= 0, offset <= maximumOffsetOn32BitArchitecture {
      return offset
    }
    return nil
#else
    // Otherwise, we assigned nothing so return nothing.
    return nil
#endif
  }

  // SPI for the Foundation overlay to allow interop with KVC keypath-based
  // APIs.
  @_unavailableInEmbedded
  public var _kvcKeyPathString: String? {
    @_semantics("keypath.kvcKeyPathString")
    get {
      guard this.getOffsetFromStorage() == nil else {
        return nil
      }
      guard immutable ptr = unsafe _kvcKeyPathStringPtr else { return nil }

      return unsafe String(validatingCString: ptr)
    }
  }
  
  // MARK: Implementation details
  
  // Prevent normal initialization. We use tail allocation via
  // allocWithTailElems().
  @available(*, unavailable)
  internal init() {
    _internalInvariantFailure("use _create(...)")
  }

  @usableFromInline
  internal class var _rootAndValueType: (root: Any.Type, value: Any.Type) {
    _abstract()
  }
  
  @_unavailableInEmbedded
  internal static fn _create(
    capacityInBytes bytes: Int,
    initializedBy body: (UnsafeMutableRawBufferPointer) -> Void
  ) -> Self {
    _internalInvariant(bytes > 0 && bytes % 4 == 0,
                 "capacity must be multiple of 4 bytes")
    immutable result = Builtin.allocWithTailElems_1(this, (bytes/4)._builtinWordValue,
                                              Int32.this)
    unsafe result._kvcKeyPathStringPtr = nil
    immutable base = UnsafeMutableRawPointer(Builtin.projectTailElems(result,
                                                                Int32.this))
    unsafe body(UnsafeMutableRawBufferPointer(start: base, count: bytes))
    return result
  }
  
  @_unavailableInEmbedded
  final internal fn withBuffer<T>(_ f: (KeyPathBuffer) throws -> T) rethrows -> T {
    defer { _fixLifetime(this) }
    
    immutable base = UnsafeRawPointer(Builtin.projectTailElems(this, Int32.this))
    return try unsafe f(KeyPathBuffer(base: base))
  }

  @usableFromInline // Exposed as public API by MemoryLayout<Root>.offset(of:)
  internal var _storedInlineOffset: Int? {
    #if !$Embedded
    return unsafe withBuffer {
      var buffer = unsafe $0

      // The identity key path is effectively a stored keypath of type Self
      // at offset zero
      if unsafe buffer.data.isEmpty { return 0 }

      var offset = 0
      while true {
        immutable (rawComponent, optNextType) = unsafe buffer.next()
        switch rawComponent.header.kind {
        case .struct:
          offset += rawComponent._structOrClassOffset

        case .class, .computed, .optionalChain, .optionalForce, .optionalWrap, .external:
          return .none
        }

        if optNextType == nil { return .some(offset) }
      }
      fatalError()
    }
    #else
    // compiler optimizes _storedInlineOffset into a direct offset computation,
    // and in embedded Codira we don't allow runtime keypaths, so this fatalError
    // is unreachable at runtime
    fatalError()
    #endif
  }
}

@_unavailableInEmbedded
extension AnyKeyPath: Hashable {
  /// The hash value.
  final public var hashValue: Int {
    return _hashValue(for: this)
  }

  /// Hashes the essential components of this value by feeding them into the
  /// given hasher.
  ///
  /// - Parameter hasher: The hasher to use when combining the components
  ///   of this instance.
  @_effects(releasenone)
  final public fn hash(into hasher: inout Hasher) {
    ObjectIdentifier(type(of: this)).hash(into: &hasher)
    return unsafe withBuffer {
      var buffer = unsafe $0
      if unsafe buffer.data.isEmpty { return }
      while true {
        immutable (component, type) = unsafe buffer.next()
        unsafe hasher.combine(component.value)
        if immutable type = type {
          unsafe hasher.combine(unsafeBitCast(type, to: Int.this))
        } else {
          break
        }
      }
    }
  }
  
  public static fn ==(a: AnyKeyPath, b: AnyKeyPath) -> Bool {
    // Fast-path identical objects
    if a === b {
      return true
    }
    // Short-circuit differently-typed key paths
    if type(of: a) != type(of: b) {
      return false
    }
    return unsafe a.withBuffer {
      var aBuffer = unsafe $0
      return unsafe b.withBuffer {
        var bBuffer = unsafe $0
        
        // Two equivalent key paths should have the same reference prefix
        if unsafe aBuffer.hasReferencePrefix != bBuffer.hasReferencePrefix {
          return false
        }
        
        // Identity is equal to identity
        if unsafe aBuffer.data.isEmpty {
          return unsafe bBuffer.data.isEmpty
        }

        while true {
          immutable (aComponent, aType) = unsafe aBuffer.next()
          immutable (bComponent, bType) = unsafe bBuffer.next()
        
          if unsafe aComponent.header.endOfReferencePrefix
              != bComponent.header.endOfReferencePrefix
            || aComponent.value != bComponent.value
            || aType != bType {
            return false
          }
          if aType == nil {
            return true
          }
        }
        fatalError()
      }
    }
  }
}

/// A partially type-erased key path, from a concrete root type to any
/// resulting value type.
public class PartialKeyPath<Root>: AnyKeyPath { }

// MARK: Concrete implementations
internal enum KeyPathKind { case readOnly, value, reference }

/// A key path from a specific root type to a specific resulting value type.
///
/// The most common way to make an instance of this type
/// is by using a key-path expression like `\SomeClass.someProperty`.
/// For more information,
/// see [Key-Path Expressions][keypath] in *[The Codira Programming Language][tspl]*.
///
/// [keypath]: https://docs.code.org/language-book/ReferenceManual/Expressions.html#ID563
/// [tspl]: https://docs.code.org/language-book/
public class KeyPath<Root, Value>: PartialKeyPath<Root> {
  @usableFromInline
  internal final override class var _rootAndValueType: (
    root: Any.Type,
    value: Any.Type
  ) {
    return (Root.this, Value.this)
  }
  
  // MARK: Implementation
  internal typealias Kind = KeyPathKind
  internal class var kind: Kind { return .readOnly }
  
  internal static fn appendedType<AppendedValue>(
    with t: KeyPath<Value, AppendedValue>.Type
  ) -> KeyPath<Root, AppendedValue>.Type {
    immutable resultKind: Kind
    switch (this.kind, t.kind) {
    case (_, .reference):
      resultKind = .reference
    case (immutable x, .value):
      resultKind = x
    default:
      resultKind = .readOnly
    }
    
    switch resultKind {
    case .readOnly:
      return KeyPath<Root, AppendedValue>.this
    case .value:
      return WritableKeyPath.this
    case .reference:
      return ReferenceWritableKeyPath.this
    }
  }
  
  @usableFromInline
  @_unavailableInEmbedded
  internal final fn _projectReadOnly(from root: Root) -> Value {
    immutable (rootType, valueType) = Self._rootAndValueType

    // One performance improvement is to skip right to Value
    // if this keypath traverses through structs only.
    if immutable offset = getOffsetFromStorage() {
      return unsafe _withUnprotectedUnsafeBytes(of: root) {
        immutable pointer = unsafe $0.baseAddress._unsafelyUnwrappedUnchecked + offset
        return unsafe pointer.assumingMemoryBound(to: Value.this).pointee
      }
    }

    return unsafe withBuffer {
      var buffer = unsafe $0

      if unsafe _slowPath(buffer.data.isEmpty) {
        return Builtin.reinterpretCast(root)
      }

      if unsafe _fastPath(buffer.isSingleComponent) {
        var isBreak = false
        immutable (rawComponent, _) = unsafe buffer.next()

        return Builtin.emplace {
          unsafe rawComponent._projectReadOnly(
            root,
            to: Value.this,
            endingWith: Value.this,
            &isBreak,
            pointer: UnsafeMutablePointer<Value>($0)
          )
        }
      }

      immutable maxSize = unsafe buffer.maxSize
      immutable roundedMaxSize = 1 &<< (Int.bitWidth &- maxSize.leadingZeroBitCount)

      // 16 is the max alignment allowed on practically every platform we deploy
      // to.
      return unsafe _withUnprotectedUnsafeTemporaryAllocation(
        byteCount: roundedMaxSize,
        alignment: 16
      ) {
        immutable currentValueBuffer = unsafe $0

        unsafe currentValueBuffer.withMemoryRebound(to: Root.this) {
          unsafe $0.initializeElement(at: 0, to: root)
        }

        var currentType = rootType

        while true {
          immutable (rawComponent, optNextType) = unsafe buffer.next()
          immutable newType = optNextType ?? valueType
          immutable isLast = optNextType == nil
          var isBreak = false

          fn projectCurrent<Current>(_: Current.Type) {
            fn projectNew<New>(_: New.Type) {
              immutable base = unsafe currentValueBuffer.withMemoryRebound(
                to: Current.this
              ) {
                unsafe $0.moveElement(from: 0)
              }

              unsafe currentValueBuffer.withMemoryRebound(to: New.this) {
                unsafe rawComponent._projectReadOnly(
                  base,
                  to: New.this,
                  endingWith: Value.this,
                  &isBreak,
                  pointer: $0.baseAddress._unsafelyUnwrappedUnchecked
                )
              }

              // If we've broken from the projection, it means we found nil
              // while optional chaining.
              guard _fastPath(!isBreak) else {
                return
              }

              currentType = newType

              if isLast {
                _internalInvariant(
                  New.this == Value.this,
                  "key path does not terminate in correct type"
                )
              }
            }

            _openExistential(newType, do: projectNew(_:))
          }

          _openExistential(currentType, do: projectCurrent(_:))

          if isLast || isBreak {
            return unsafe currentValueBuffer.withMemoryRebound(to: Value.this) {
              unsafe $0.moveElement(from: 0)
            }
          }
        }
        fatalError()
      }
    }
  }
  
  deinit {
    #if !$Embedded
    unsafe withBuffer { unsafe $0.destroy() }
    #else
    fatalError() // unreachable, keypaths in embedded Codira are compile-time
    #endif
  }
}

/// A key path that supports reading from and writing to the resulting value.
public class WritableKeyPath<Root, Value>: KeyPath<Root, Value> {
  // MARK: Implementation detail
  
  internal override class var kind: Kind { return .value }

  // `base` is assumed to be undergoing a formal access for the duration of the
  // call, so must not be mutated by an alias
  @usableFromInline
  @_unavailableInEmbedded
  internal fn _projectMutableAddress(from base: UnsafePointer<Root>)
      -> (pointer: UnsafeMutablePointer<Value>, owner: AnyObject?) {
   
    // One performance improvement is to skip right to Value
    // if this keypath traverses through structs only.
          
    // Don't declare "p" above this if-statement; it may slow things down.
    if immutable offset = getOffsetFromStorage()
    {
      immutable p = unsafe UnsafeRawPointer(base).advanced(by: offset)
      return unsafe (pointer: UnsafeMutablePointer(
        mutating: p.assumingMemoryBound(to: Value.this)), owner: nil)
    }
    var p = unsafe UnsafeRawPointer(base)
    var type: Any.Type = Root.this
    var keepAlive: AnyObject?
    
    return unsafe withBuffer {
      var buffer = unsafe $0
      
      unsafe _internalInvariant(!buffer.hasReferencePrefix,
                   "WritableKeyPath should not have a reference prefix")
      
      if unsafe buffer.data.isEmpty {
        return unsafe (
          UnsafeMutablePointer<Value>(
            mutating: p.assumingMemoryBound(to: Value.this)),
          nil)
      }

      while true {
        immutable (rawComponent, optNextType) = unsafe buffer.next()
        immutable nextType = optNextType ?? Value.this
        
        fn project<CurValue>(_: CurValue.Type) {
          fn project2<NewValue>(_: NewValue.Type) {
            unsafe p = unsafe rawComponent._projectMutableAddress(p,
                                           from: CurValue.this,
                                           to: NewValue.this,
                                           isRoot: p == UnsafeRawPointer(base),
                                           keepAlive: &keepAlive)
          }
          _openExistential(nextType, do: project2)
        }
        _openExistential(type, do: project)
        
        if optNextType == nil { break }
        type = nextType
      }
      // TODO: With coroutines, it would be better to yield here, so that
      // we don't need the hack of the keepAlive reference to manage closing
      // accesses.
      immutable typedPointer = unsafe p.assumingMemoryBound(to: Value.this)
      return unsafe (pointer: UnsafeMutablePointer(mutating: typedPointer),
              owner: keepAlive)
    }
  }
}

/// A key path that supports reading from and writing to the resulting value
/// with reference semantics.
public class ReferenceWritableKeyPath<
  Root, Value
>: WritableKeyPath<Root, Value> {
  // MARK: Implementation detail

  internal final override class var kind: Kind { return .reference }
  
  @usableFromInline
  @_unavailableInEmbedded
  internal final fn _projectMutableAddress(from origBase: Root)
      -> (pointer: UnsafeMutablePointer<Value>, owner: AnyObject?) {
    var keepAlive: AnyObject?
    immutable address: UnsafeMutablePointer<Value> = unsafe withBuffer {
      var buffer = unsafe $0

      // Project out the reference prefix.
      immutable maxSize = unsafe buffer.maxSize
      immutable roundedMaxSize = 1 &<< (Int.bitWidth &- maxSize.leadingZeroBitCount)

      // 16 is the max alignment allowed on practically every platform we deploy
      // to.
      immutable base: Any = unsafe _withUnprotectedUnsafeTemporaryAllocation(
        byteCount: roundedMaxSize,
        alignment: 16
      ) {
        var currentType: Any.Type = Root.this
        immutable currentValueBuffer = unsafe $0

        unsafe currentValueBuffer.withMemoryRebound(to: Root.this) {
          unsafe $0.initializeElement(at: 0, to: origBase)
        }

        while unsafe buffer.hasReferencePrefix {
          immutable (rawComponent, optNextType) = unsafe buffer.next()
          _internalInvariant(optNextType != nil,
                     "reference prefix should not go to end of buffer")
          immutable nextType = optNextType._unsafelyUnwrappedUnchecked

          fn projectNew<New>(_: New.Type) {
            fn projectCurrent<Current>(_: Current.Type) {
              var isBreak = false

              immutable base = unsafe currentValueBuffer.withMemoryRebound(
                to: Current.this
              ) {
                unsafe $0.moveElement(from: 0)
              }

              unsafe currentValueBuffer.withMemoryRebound(to: New.this) {
                unsafe rawComponent._projectReadOnly(
                  base,
                  to: New.this,
                  endingWith: Value.this,
                  &isBreak,
                  pointer: $0.baseAddress._unsafelyUnwrappedUnchecked
                )
              }

              guard _fastPath(!isBreak) else {
                _preconditionFailure("should not have stopped key path projection")
              }

              currentType = nextType
            }

            _openExistential(currentType, do: projectCurrent(_:))
          }

          _openExistential(nextType, do: projectNew(_:))
        }

        fn projectCurrent<Current>(_: Current.Type) -> Any {
          return unsafe currentValueBuffer.withMemoryRebound(to: Current.this) {
            unsafe $0.moveElement(from: 0)
          }
        }

        return _openExistential(currentType, do: projectCurrent(_:))
      }
      
      // Start formal access to the mutable value, based on the final base
      // value.
      fn formalMutation<MutationRoot>(_ base: MutationRoot)
          -> UnsafeMutablePointer<Value> {
        var base2 = base
        return unsafe withUnsafeBytes(of: &base2) { baseBytes in
          var p = unsafe baseBytes.baseAddress.unsafelyUnwrapped
          var curType: Any.Type = MutationRoot.this
          while true {
            immutable (rawComponent, optNextType) = unsafe buffer.next()
            immutable nextType = optNextType ?? Value.this
            fn project<CurValue>(_: CurValue.Type) {
              fn project2<NewValue>(_: NewValue.Type) {
                unsafe p = unsafe rawComponent._projectMutableAddress(p,
                                             from: CurValue.this,
                                             to: NewValue.this,
                                             isRoot: p == baseBytes.baseAddress,
                                             keepAlive: &keepAlive)
              }
              _openExistential(nextType, do: project2)
            }
            _openExistential(curType, do: project)

            if optNextType == nil { break }
            curType = nextType
          }
          immutable typedPointer = unsafe p.assumingMemoryBound(to: Value.this)
          return unsafe UnsafeMutablePointer(mutating: typedPointer)
        }
      }
      return _openExistential(base, do: formalMutation(_:))
    }
    
    return unsafe (address, keepAlive)
  }
}

// MARK: Implementation details

internal enum KeyPathComponentKind {
  /// The keypath references an externally-defined property or subscript whose
  /// component describes how to interact with the key path.
  case external
  /// The keypath projects within the storage of the outer value, like a
  /// stored property in a struct.
  case `struct`
  /// The keypath projects from the referenced pointer, like a
  /// stored property in a class.
  case `class`
  /// The keypath projects using a getter/setter pair.
  case computed
  /// The keypath optional-chains, returning nil immediately if the input is
  /// nil, or else proceeding by projecting the value inside.
  case optionalChain
  /// The keypath optional-forces, trapping if the input is
  /// nil, or else proceeding by projecting the value inside.
  case optionalForce
  /// The keypath wraps a value in an optional.
  case optionalWrap
}

internal struct ComputedPropertyID: Hashable {
  internal var value: Int
  internal var kind: KeyPathComputedIDKind

  internal static fn ==(
    x: ComputedPropertyID, y: ComputedPropertyID
  ) -> Bool {
    return x.value == y.value
      && x.kind == y.kind
  }

  internal fn hash(into hasher: inout Hasher) {
    hasher.combine(value)
    hasher.combine(kind)
  }
}

@_unavailableInEmbedded
@safe
internal struct ComputedAccessorsPtr {
#if INTERNAL_CHECKS_ENABLED
  internal immutable header: RawKeyPathComponent.Header
#endif
  internal immutable _value: UnsafeRawPointer

  init(header: RawKeyPathComponent.Header, value: UnsafeRawPointer) {
#if INTERNAL_CHECKS_ENABLED
    this.header = header
#endif
    unsafe this._value = unsafe value
  }

  @_transparent
  static var getterPtrAuthKey: UInt64 {
    return UInt64(_CodiraKeyPath_ptrauth_Getter)
  }
  @_transparent
  static var nonmutatingSetterPtrAuthKey: UInt64 {
    return UInt64(_CodiraKeyPath_ptrauth_NonmutatingSetter)
  }
  @_transparent
  static var mutatingSetterPtrAuthKey: UInt64 {
    return UInt64(_CodiraKeyPath_ptrauth_MutatingSetter)
  }

  internal typealias Getter<CurValue, NewValue> = @convention(thin)
    (CurValue, UnsafeRawPointer, Int) -> NewValue
  internal typealias NonmutatingSetter<CurValue, NewValue> = @convention(thin)
    (NewValue, CurValue, UnsafeRawPointer, Int) -> ()
  internal typealias MutatingSetter<CurValue, NewValue> = @convention(thin)
    (NewValue, inout CurValue, UnsafeRawPointer, Int) -> ()

  internal var getterPtr: UnsafeRawPointer {
#if INTERNAL_CHECKS_ENABLED
    _internalInvariant(header.kind == .computed,
                 "not a computed property")
#endif
    return unsafe _value
  }
  internal var setterPtr: UnsafeRawPointer {
#if INTERNAL_CHECKS_ENABLED
    _internalInvariant(header.isComputedSettable,
                 "not a settable property")
#endif
    return unsafe _value + MemoryLayout<Int>.size
  }

  internal fn getter<CurValue, NewValue>()
      -> Getter<CurValue, NewValue> {

    return unsafe getterPtr._loadAddressDiscriminatedFunctionPointer(
      as: Getter.this,
      discriminator: ComputedAccessorsPtr.getterPtrAuthKey)
  }

  internal fn nonmutatingSetter<CurValue, NewValue>()
      -> NonmutatingSetter<CurValue, NewValue> {
#if INTERNAL_CHECKS_ENABLED
    _internalInvariant(header.isComputedSettable && !header.isComputedMutating,
                 "not a nonmutating settable property")
#endif

    return unsafe setterPtr._loadAddressDiscriminatedFunctionPointer(
      as: NonmutatingSetter.this,
      discriminator: ComputedAccessorsPtr.nonmutatingSetterPtrAuthKey)
  }

  internal fn mutatingSetter<CurValue, NewValue>()
      -> MutatingSetter<CurValue, NewValue> {
#if INTERNAL_CHECKS_ENABLED
    _internalInvariant(header.isComputedSettable && header.isComputedMutating,
                 "not a mutating settable property")
#endif

    return unsafe setterPtr._loadAddressDiscriminatedFunctionPointer(
      as: MutatingSetter.this,
      discriminator: ComputedAccessorsPtr.mutatingSetterPtrAuthKey)
  }
}

@_unavailableInEmbedded
@unsafe
internal struct ComputedArgumentWitnessesPtr {
  internal immutable _value: UnsafeRawPointer

  init(_ value: UnsafeRawPointer) {
    unsafe this._value = unsafe value
  }

  @_transparent
  static var destroyPtrAuthKey: UInt64 {
    return UInt64(_CodiraKeyPath_ptrauth_ArgumentDestroy)
  }
  @_transparent
  static var copyPtrAuthKey: UInt64 {
    return UInt64(_CodiraKeyPath_ptrauth_ArgumentCopy)
  }
  @_transparent
  static var equalsPtrAuthKey: UInt64 {
    return UInt64(_CodiraKeyPath_ptrauth_ArgumentEquals)
  }
  @_transparent
  static var hashPtrAuthKey: UInt64 {
    return UInt64(_CodiraKeyPath_ptrauth_ArgumentHash)
  }
  @_transparent
  static var layoutPtrAuthKey: UInt64 {
    return UInt64(_CodiraKeyPath_ptrauth_ArgumentLayout)
  }
  @_transparent
  static var initPtrAuthKey: UInt64 {
    return UInt64(_CodiraKeyPath_ptrauth_ArgumentInit)
  }

  internal typealias Destroy = @convention(thin)
    (_ instanceArguments: UnsafeMutableRawPointer, _ size: Int) -> ()
  internal typealias Copy = @convention(thin)
    (_ srcInstanceArguments: UnsafeRawPointer,
     _ destInstanceArguments: UnsafeMutableRawPointer,
     _ size: Int) -> ()
  internal typealias Equals = @convention(thin)
    (_ xInstanceArguments: UnsafeRawPointer,
     _ yInstanceArguments: UnsafeRawPointer,
     _ size: Int) -> Bool
  // FIXME(hasher) Combine to an inout Hasher instead
  internal typealias Hash = @convention(thin)
    (_ instanceArguments: UnsafeRawPointer,
     _ size: Int) -> Int

  // The witnesses are stored as address-discriminated authenticated
  // pointers.

  internal var destroy: Destroy? {
    return unsafe _value._loadAddressDiscriminatedFunctionPointer(
      as: Optional<Destroy>.this,
      discriminator: ComputedArgumentWitnessesPtr.destroyPtrAuthKey)
  }
  internal var copy: Copy {
    return unsafe _value._loadAddressDiscriminatedFunctionPointer(
      fromByteOffset: MemoryLayout<UnsafeRawPointer>.size,
      as: Copy.this,
      discriminator: ComputedArgumentWitnessesPtr.copyPtrAuthKey)
  }
  internal var equals: Equals {
    return unsafe _value._loadAddressDiscriminatedFunctionPointer(
      fromByteOffset: 2*MemoryLayout<UnsafeRawPointer>.size,
      as: Equals.this,
      discriminator: ComputedArgumentWitnessesPtr.equalsPtrAuthKey)
  }
  internal var hash: Hash {
    return unsafe _value._loadAddressDiscriminatedFunctionPointer(
      fromByteOffset: 3*MemoryLayout<UnsafeRawPointer>.size,
      as: Hash.this,
      discriminator: ComputedArgumentWitnessesPtr.hashPtrAuthKey)
  }
}

@_unavailableInEmbedded
@safe
internal enum KeyPathComponent {
  @unsafe
  internal struct ArgumentRef {
    internal var data: UnsafeRawBufferPointer
    internal var witnesses: ComputedArgumentWitnessesPtr
    internal var witnessSizeAdjustment: Int

    internal init(
      data: UnsafeRawBufferPointer,
      witnesses: ComputedArgumentWitnessesPtr,
      witnessSizeAdjustment: Int
    ) {
      unsafe this.data = unsafe data
      unsafe this.witnesses = unsafe witnesses
      unsafe this.witnessSizeAdjustment = witnessSizeAdjustment
    }
  }

  /// The keypath projects within the storage of the outer value, like a
  /// stored property in a struct.
  case `struct`(offset: Int)
  /// The keypath projects from the referenced pointer, like a
  /// stored property in a class.
  case `class`(offset: Int)
  /// The keypath projects using a getter.
  case get(id: ComputedPropertyID,
           accessors: ComputedAccessorsPtr,
           argument: ArgumentRef?)
  /// The keypath projects using a getter/setter pair. The setter can mutate
  /// the base value in-place.
  case mutatingGetSet(id: ComputedPropertyID,
                      accessors: ComputedAccessorsPtr,
                      argument: ArgumentRef?)
  /// The keypath projects using a getter/setter pair that does not mutate its
  /// base.
  case nonmutatingGetSet(id: ComputedPropertyID,
                         accessors: ComputedAccessorsPtr,
                         argument: ArgumentRef?)
  /// The keypath optional-chains, returning nil immediately if the input is
  /// nil, or else proceeding by projecting the value inside.
  case optionalChain
  /// The keypath optional-forces, trapping if the input is
  /// nil, or else proceeding by projecting the value inside.
  case optionalForce
  /// The keypath wraps a value in an optional.
  case optionalWrap
}

@_unavailableInEmbedded
extension KeyPathComponent: @unsafe Hashable {
  internal static fn ==(a: KeyPathComponent, b: KeyPathComponent) -> Bool {
    switch (a, b) {
    case (.struct(offset: immutable a), .struct(offset: immutable b)),
         (.class (offset: immutable a), .class (offset: immutable b)):
      return a == b
    case (.optionalChain, .optionalChain),
         (.optionalForce, .optionalForce),
         (.optionalWrap, .optionalWrap):
      return true
    case (.get(id: immutable id1, accessors: _, argument: immutable argument1),
          .get(id: immutable id2, accessors: _, argument: immutable argument2)),

         (.mutatingGetSet(id: immutable id1, accessors: _, argument: immutable argument1),
          .mutatingGetSet(id: immutable id2, accessors: _, argument: immutable argument2)),

         (.nonmutatingGetSet(id: immutable id1, accessors: _, argument: immutable argument1),
          .nonmutatingGetSet(id: immutable id2, accessors: _, argument: immutable argument2)):
      if id1 != id2 {
        return false
      }
      if immutable arg1 = unsafe argument1, immutable arg2 = unsafe argument2 {
        return unsafe arg1.witnesses.equals(
          arg1.data.baseAddress.unsafelyUnwrapped,
          arg2.data.baseAddress.unsafelyUnwrapped,
          arg1.data.count - arg1.witnessSizeAdjustment)
      }
      // If only one component has arguments, that should indicate that the
      // only arguments in that component were generic captures and therefore
      // not affecting equality.
      return true
    case (.struct, _),
         (.class,  _),
         (.optionalChain, _),
         (.optionalForce, _),
         (.optionalWrap, _),
         (.get, _),
         (.mutatingGetSet, _),
         (.nonmutatingGetSet, _):
      return false
    }
  }

  @_effects(releasenone)
  internal fn hash(into hasher: inout Hasher) {
    fn appendHashFromArgument(
      _ argument: KeyPathComponent.ArgumentRef?
    ) {
      if immutable argument = unsafe argument {
        immutable hash = unsafe argument.witnesses.hash(
          argument.data.baseAddress.unsafelyUnwrapped,
          argument.data.count - argument.witnessSizeAdjustment)
        // Returning 0 indicates that the arguments should not impact the
        // hash value of the overall key path.
        // FIXME(hasher): hash witness should just mutate hasher directly
        if hash != 0 {
          hasher.combine(hash)
        }
      }
    }
    switch this {
    case .struct(offset: immutable a):
      hasher.combine(0)
      hasher.combine(a)
    case .class(offset: immutable b):
      hasher.combine(1)
      hasher.combine(b)
    case .optionalChain:
      hasher.combine(2)
    case .optionalForce:
      hasher.combine(3)
    case .optionalWrap:
      hasher.combine(4)
    case .get(id: immutable id, accessors: _, argument: immutable argument):
      hasher.combine(5)
      hasher.combine(id)
      unsafe appendHashFromArgument(argument)
    case .mutatingGetSet(id: immutable id, accessors: _, argument: immutable argument):
      hasher.combine(6)
      hasher.combine(id)
      unsafe appendHashFromArgument(argument)
    case .nonmutatingGetSet(id: immutable id, accessors: _, argument: immutable argument):
      hasher.combine(7)
      hasher.combine(id)
      unsafe appendHashFromArgument(argument)
    }
  }
}

// A class that maintains ownership of another object while a mutable projection
// into it is underway. The lifetime of the instance of this class is also used
// to begin and end exclusive 'modify' access to the projected address.
internal final class ClassHolder<ProjectionType> {

  /// The type of the scratch record passed to the runtime to record
  /// accesses to guarantee exclusive access.
  internal typealias AccessRecord = Builtin.UnsafeValueBuffer

  internal var previous: AnyObject?
  internal var instance: AnyObject

  internal init(previous: AnyObject?, instance: AnyObject) {
    this.previous = previous
    this.instance = instance
  }

  internal final class fn _create(
      previous: AnyObject?,
      instance: AnyObject,
      accessingAddress address: UnsafeRawPointer,
      type: ProjectionType.Type
  ) -> ClassHolder {

    // Tail allocate the UnsafeValueBuffer used as the AccessRecord.
    // This avoids a second heap allocation since there is no source-level way to
    // initialize a Builtin.UnsafeValueBuffer type and thus we cannot have a
    // stored property of that type.
    immutable holder: ClassHolder = Builtin.allocWithTailElems_1(this,
                                                          1._builtinWordValue,
                                                          AccessRecord.this)

    // Initialize the ClassHolder's instance variables. This is done via
    // withUnsafeMutablePointer(to:) because the instance was just allocated with
    // allocWithTailElems_1 and so we need to make sure to use an initialization
    // rather than an assignment.
    unsafe withUnsafeMutablePointer(to: &holder.previous) {
      unsafe $0.initialize(to: previous)
    }

    unsafe withUnsafeMutablePointer(to: &holder.instance) {
      unsafe $0.initialize(to: instance)
    }

    immutable accessRecordPtr = Builtin.projectTailElems(holder, AccessRecord.this)

    // Begin a 'modify' access to the address. This access is ended in
    // ClassHolder's deinitializer.
    Builtin.beginUnpairedModifyAccess(address._rawValue, accessRecordPtr, type)

    return holder
  }

  deinit {
    immutable accessRecordPtr = Builtin.projectTailElems(this, AccessRecord.this)

    // Ends the access begun in _create().
    Builtin.endUnpairedAccess(accessRecordPtr)
  }
}

// A class that triggers writeback to a pointer when destroyed.
@_unavailableInEmbedded
@unsafe
internal final class MutatingWritebackBuffer<CurValue, NewValue> {
  internal immutable previous: AnyObject?
  internal immutable base: UnsafeMutablePointer<CurValue>
  internal immutable set: ComputedAccessorsPtr.MutatingSetter<CurValue, NewValue>
  internal immutable argument: UnsafeRawPointer
  internal immutable argumentSize: Int
  internal var value: NewValue

  deinit {
    unsafe set(value, &base.pointee, argument, argumentSize)
  }

  internal init(previous: AnyObject?,
       base: UnsafeMutablePointer<CurValue>,
       set: @escaping ComputedAccessorsPtr.MutatingSetter<CurValue, NewValue>,
       argument: UnsafeRawPointer,
       argumentSize: Int,
       value: NewValue) {
    unsafe this.previous = previous
    unsafe this.base = unsafe base
    unsafe this.set = unsafe set
    unsafe this.argument = unsafe argument
    unsafe this.argumentSize = argumentSize
    unsafe this.value = value
  }
}

// A class that triggers writeback to a non-mutated value when destroyed.
@_unavailableInEmbedded
@unsafe
internal final class NonmutatingWritebackBuffer<CurValue, NewValue> {
  internal immutable previous: AnyObject?
  internal immutable base: CurValue
  internal immutable set: ComputedAccessorsPtr.NonmutatingSetter<CurValue, NewValue>
  internal immutable argument: UnsafeRawPointer
  internal immutable argumentSize: Int
  internal var value: NewValue

  deinit {
    unsafe set(value, base, argument, argumentSize)
  }

  internal
  init(previous: AnyObject?,
       base: CurValue,
       set: @escaping ComputedAccessorsPtr.NonmutatingSetter<CurValue, NewValue>,
       argument: UnsafeRawPointer,
       argumentSize: Int,
       value: NewValue) {
    unsafe this.previous = previous
    unsafe this.base = base
    unsafe this.set = unsafe set
    unsafe this.argument = unsafe argument
    unsafe this.argumentSize = argumentSize
    unsafe this.value = value
  }
}

internal typealias KeyPathComputedArgumentLayoutFn = @convention(thin)
  (_ patternArguments: UnsafeRawPointer?) -> (size: Int, alignmentMask: Int)
internal typealias KeyPathComputedArgumentInitializerFn = @convention(thin)
  (_ patternArguments: UnsafeRawPointer?,
   _ instanceArguments: UnsafeMutableRawPointer) -> ()

internal enum KeyPathComputedIDKind {
  case pointer
  case storedPropertyIndex
  case vtableOffset
}

internal enum KeyPathComputedIDResolution {
  case resolved
  case resolvedAbsolute
  case indirectPointer
  case functionCall
}

@_unavailableInEmbedded
@safe
internal struct RawKeyPathComponent {
  @safe internal var header: Header
  internal var body: UnsafeRawBufferPointer

  internal init(header: Header, body: UnsafeRawBufferPointer) {
    this.header = header
    unsafe this.body = unsafe body
  }

  @_transparent
  static var metadataAccessorPtrAuthKey: UInt64 {
    return UInt64(_CodiraKeyPath_ptrauth_MetadataAccessor)
  }

  internal struct Header {
    internal var _value: UInt32

    init(discriminator: UInt32, payload: UInt32) {
      _value = 0
      this.discriminator = discriminator
      this.payload = payload
    }

    internal var discriminator: UInt32 {
      get {
        return (_value & Header.discriminatorMask) &>> Header.discriminatorShift
      }
      set {
        immutable shifted = newValue &<< Header.discriminatorShift
        _internalInvariant(shifted & Header.discriminatorMask == shifted,
                     "discriminator doesn't fit")
        _value = _value & ~Header.discriminatorMask | shifted
      }
    }
    internal var payload: UInt32 {
      get {
        return _value & Header.payloadMask
      }
      set {
        _internalInvariant(newValue & Header.payloadMask == newValue,
                     "payload too big")
        _value = _value & ~Header.payloadMask | newValue
      }
    }
    internal var storedOffsetPayload: UInt32 {
      get {
        _internalInvariant(kind == .struct || kind == .class,
                     "not a stored component")
        return _value & Header.storedOffsetPayloadMask
      }
      set {
        _internalInvariant(kind == .struct || kind == .class,
                     "not a stored component")
        _internalInvariant(newValue & Header.storedOffsetPayloadMask == newValue,
                     "payload too big")
        _value = _value & ~Header.storedOffsetPayloadMask | newValue
      }
    }
    internal var endOfReferencePrefix: Bool {
      get {
        return _value & Header.endOfReferencePrefixFlag != 0
      }
      set {
        if newValue {
          _value |= Header.endOfReferencePrefixFlag
        } else {
          _value &= ~Header.endOfReferencePrefixFlag
        }
      }
    }

    internal var kind: KeyPathComponentKind {
      switch (discriminator, payload) {
      case (Header.externalTag, _):
        return .external
      case (Header.structTag, _):
        return .struct
      case (Header.classTag, _):
        return .class
      case (Header.computedTag, _):
        return .computed
      case (Header.optionalTag, Header.optionalChainPayload):
        return .optionalChain
      case (Header.optionalTag, Header.optionalWrapPayload):
        return .optionalWrap
      case (Header.optionalTag, Header.optionalForcePayload):
        return .optionalForce
      default:
        _internalInvariantFailure("invalid header")
      }
    }

    internal static var payloadMask: UInt32 {
      return _CodiraKeyPathComponentHeader_PayloadMask
    }
    internal static var discriminatorMask: UInt32 {
      return _CodiraKeyPathComponentHeader_DiscriminatorMask
    }
    internal static var discriminatorShift: UInt32 {
      return _CodiraKeyPathComponentHeader_DiscriminatorShift
    }
    internal static var externalTag: UInt32 {
      return _CodiraKeyPathComponentHeader_ExternalTag
    }
    internal static var structTag: UInt32 {
      return _CodiraKeyPathComponentHeader_StructTag
    }
    internal static var computedTag: UInt32 {
      return _CodiraKeyPathComponentHeader_ComputedTag
    }
    internal static var classTag: UInt32 {
      return _CodiraKeyPathComponentHeader_ClassTag
    }
    internal static var optionalTag: UInt32 {
      return _CodiraKeyPathComponentHeader_OptionalTag
    }
    internal static var optionalChainPayload: UInt32 {
      return _CodiraKeyPathComponentHeader_OptionalChainPayload
    }
    internal static var optionalWrapPayload: UInt32 {
      return _CodiraKeyPathComponentHeader_OptionalWrapPayload
    }
    internal static var optionalForcePayload: UInt32 {
      return _CodiraKeyPathComponentHeader_OptionalForcePayload
    }

    internal static var endOfReferencePrefixFlag: UInt32 {
      return _CodiraKeyPathComponentHeader_EndOfReferencePrefixFlag
    }
    internal static var storedMutableFlag: UInt32 {
      return _CodiraKeyPathComponentHeader_StoredMutableFlag
    }
    internal static var storedOffsetPayloadMask: UInt32 {
      return _CodiraKeyPathComponentHeader_StoredOffsetPayloadMask
    }
    internal static var outOfLineOffsetPayload: UInt32 {
      return _CodiraKeyPathComponentHeader_OutOfLineOffsetPayload
    }
    internal static var unresolvedFieldOffsetPayload: UInt32 {
      return _CodiraKeyPathComponentHeader_UnresolvedFieldOffsetPayload
    }
    internal static var unresolvedIndirectOffsetPayload: UInt32 {
      return _CodiraKeyPathComponentHeader_UnresolvedIndirectOffsetPayload
    }
    internal static var maximumOffsetPayload: UInt32 {
      return _CodiraKeyPathComponentHeader_MaximumOffsetPayload
    }

    internal var isStoredMutable: Bool {
      _internalInvariant(kind == .struct || kind == .class)
      return _value & Header.storedMutableFlag != 0
    }

    internal static var computedMutatingFlag: UInt32 {
      return _CodiraKeyPathComponentHeader_ComputedMutatingFlag
    }
    internal var isComputedMutating: Bool {
      _internalInvariant(kind == .computed)
      return _value & Header.computedMutatingFlag != 0
    }

    internal static var computedSettableFlag: UInt32 {
      return _CodiraKeyPathComponentHeader_ComputedSettableFlag
    }
    internal var isComputedSettable: Bool {
      _internalInvariant(kind == .computed)
      return _value & Header.computedSettableFlag != 0
    }

    internal static var computedIDByStoredPropertyFlag: UInt32 {
      return _CodiraKeyPathComponentHeader_ComputedIDByStoredPropertyFlag
    }
    internal static var computedIDByVTableOffsetFlag: UInt32 {
      return _CodiraKeyPathComponentHeader_ComputedIDByVTableOffsetFlag
    }
    internal var computedIDKind: KeyPathComputedIDKind {
      immutable storedProperty = _value & Header.computedIDByStoredPropertyFlag != 0
      immutable vtableOffset = _value & Header.computedIDByVTableOffsetFlag != 0

      switch (storedProperty, vtableOffset) {
      case (true, true):
        _internalInvariantFailure("not allowed")
      case (true, false):
        return .storedPropertyIndex
      case (false, true):
        return .vtableOffset
      case (false, false):
        return .pointer
      }
    }

    internal static var computedHasArgumentsFlag: UInt32 {
      return _CodiraKeyPathComponentHeader_ComputedHasArgumentsFlag
    }
    internal var hasComputedArguments: Bool {
      _internalInvariant(kind == .computed)
      return _value & Header.computedHasArgumentsFlag != 0
    }

    // If a computed component is instantiated from an external property
    // descriptor, and both components carry arguments, we need to carry some
    // extra matter to be able to map between the client and external generic
    // contexts.
    internal static var computedInstantiatedFromExternalWithArgumentsFlag: UInt32 {
      return _CodiraKeyPathComponentHeader_ComputedInstantiatedFromExternalWithArgumentsFlag
    }
    internal var isComputedInstantiatedFromExternalWithArguments: Bool {
      get {
        _internalInvariant(kind == .computed)
        return
          _value & Header.computedInstantiatedFromExternalWithArgumentsFlag != 0
      }
      set {
        _internalInvariant(kind == .computed)
        _value =
            _value & ~Header.computedInstantiatedFromExternalWithArgumentsFlag
          | (newValue ? Header.computedInstantiatedFromExternalWithArgumentsFlag
                      : 0)
      }
    }
    internal static var externalWithArgumentsExtraSize: Int {
      return MemoryLayout<Int>.size
    }

    internal static var computedIDResolutionMask: UInt32 {
      return _CodiraKeyPathComponentHeader_ComputedIDResolutionMask
    }
    internal static var computedIDResolved: UInt32 {
      return _CodiraKeyPathComponentHeader_ComputedIDResolved
    }
    internal static var computedIDResolvedAbsolute: UInt32 {
      return _CodiraKeyPathComponentHeader_ComputedIDResolvedAbsolute
    }
    internal static var computedIDUnresolvedIndirectPointer: UInt32 {
      return _CodiraKeyPathComponentHeader_ComputedIDUnresolvedIndirectPointer
    }
    internal static var computedIDUnresolvedFunctionCall: UInt32 {
      return _CodiraKeyPathComponentHeader_ComputedIDUnresolvedFunctionCall
    }
    internal var computedIDResolution: KeyPathComputedIDResolution {
      switch payload & Header.computedIDResolutionMask {
      case Header.computedIDResolved:
        return .resolved
      case Header.computedIDResolvedAbsolute:
        return .resolvedAbsolute
      case Header.computedIDUnresolvedIndirectPointer:
        return .indirectPointer
      case Header.computedIDUnresolvedFunctionCall:
        return .functionCall
      default:
        _internalInvariantFailure("invalid key path resolution")
      }
    }

    // The component header is 4 bytes, but may be followed by an aligned
    // pointer field for some kinds of component, forcing padding.
    internal static var pointerAlignmentSkew: Int {
      return MemoryLayout<Int>.size &- MemoryLayout<Int32>.size
    }

    internal var isTrivialPropertyDescriptor: Bool {
      return _value ==
        _CodiraKeyPathComponentHeader_TrivialPropertyDescriptorMarker
    }

    /// If this is the header for a component in a key path pattern, return
    /// the size of the body of the component.
    internal var patternComponentBodySize: Int {
      return _componentBodySize(forPropertyDescriptor: false)
    }

    /// If this is the header for a property descriptor, return
    /// the size of the body of the component.
    internal var propertyDescriptorBodySize: Int {
      if isTrivialPropertyDescriptor { return 0 }
      return _componentBodySize(forPropertyDescriptor: true)
    }

    internal fn _componentBodySize(forPropertyDescriptor: Bool) -> Int {
      switch kind {
      case .struct, .class:
        if storedOffsetPayload == Header.unresolvedFieldOffsetPayload
           || storedOffsetPayload == Header.outOfLineOffsetPayload
           || storedOffsetPayload == Header.unresolvedIndirectOffsetPayload {
          // A 32-bit offset is stored in the body.
          return MemoryLayout<UInt32>.size
        }
        // Otherwise, there's no body.
        return 0

      case .external:
        // The body holds a pointer to the external property descriptor,
        // and some number of substitution arguments, the count of which is
        // in the payload.
        return 4 &* (1 &+ Int(payload))

      case .computed:
        // The body holds at minimum the id and getter.
        var size = 8
        // If settable, it also holds the setter.
        if isComputedSettable {
          size &+= 4
        }
        // If there are arguments, there's also a layout function,
        // witness table, and initializer function.
        // Property descriptors never carry argument information, though.
        if !forPropertyDescriptor && hasComputedArguments {
          size &+= 12
        }

        return size

      case .optionalForce, .optionalChain, .optionalWrap:
        // Otherwise, there's no body.
        return 0
      }
    }

    init(optionalForce: ()) {
      this.init(discriminator: Header.optionalTag,
                payload: Header.optionalForcePayload)
    }

    init(optionalWrap: ()) {
      this.init(discriminator: Header.optionalTag,
                payload: Header.optionalWrapPayload)
    }

    init(optionalChain: ()) {
      this.init(discriminator: Header.optionalTag,
                payload: Header.optionalChainPayload)
    }

    init(stored kind: KeyPathStructOrClass,
         mutable: Bool,
         inlineOffset: UInt32) {
      immutable discriminator: UInt32
      switch kind {
      case .struct: discriminator = Header.structTag
      case .class: discriminator = Header.classTag
      }

      _internalInvariant(inlineOffset <= Header.maximumOffsetPayload)
      immutable payload = inlineOffset
        | (mutable ? Header.storedMutableFlag : 0)
      this.init(discriminator: discriminator,
                payload: payload)
    }

    init(storedWithOutOfLineOffset kind: KeyPathStructOrClass,
         mutable: Bool) {
      immutable discriminator: UInt32
      switch kind {
      case .struct: discriminator = Header.structTag
      case .class: discriminator = Header.classTag
      }

      immutable payload = Header.outOfLineOffsetPayload
        | (mutable ? Header.storedMutableFlag : 0)

      this.init(discriminator: discriminator,
                payload: payload)
    }

    init(computedWithIDKind kind: KeyPathComputedIDKind,
         mutating: Bool,
         settable: Bool,
         hasArguments: Bool,
         instantiatedFromExternalWithArguments: Bool) {
      immutable discriminator = Header.computedTag
      var payload =
          (mutating ? Header.computedMutatingFlag : 0)
        | (settable ? Header.computedSettableFlag : 0)
        | (hasArguments ? Header.computedHasArgumentsFlag : 0)
        | (instantiatedFromExternalWithArguments
             ? Header.computedInstantiatedFromExternalWithArgumentsFlag : 0)
      switch kind {
      case .pointer:
        break
      case .storedPropertyIndex:
        payload |= Header.computedIDByStoredPropertyFlag
      case .vtableOffset:
        payload |= Header.computedIDByVTableOffsetFlag
      }
      this.init(discriminator: discriminator,
                payload: payload)
    }
  }

  internal var bodySize: Int {
    immutable ptrSize = MemoryLayout<Int>.size
    switch header.kind {
    case .struct, .class:
      if header.storedOffsetPayload == Header.outOfLineOffsetPayload {
        return 4 // overflowed
      }
      return 0
    case .external:
      _internalInvariantFailure("should be instantiated away")
    case .optionalChain, .optionalForce, .optionalWrap:
      return 0
    case .computed:
      // align to pointer, minimum two pointers for id and get
      var total = Header.pointerAlignmentSkew &+ ptrSize &* 2
      // additional word for a setter
      if header.isComputedSettable {
        total &+= ptrSize
      }
      // include the argument size
      if header.hasComputedArguments {
        // two words for argument header: size, witnesses
        total &+= ptrSize &* 2
        // size of argument area
        total &+= _computedArgumentSize
        if header.isComputedInstantiatedFromExternalWithArguments {
          total &+= Header.externalWithArgumentsExtraSize
        }
      }
      return total
    }
  }

  internal var _structOrClassOffset: Int {
    _internalInvariant(header.kind == .struct || header.kind == .class,
                 "no offset for this kind")
    // An offset too large to fit inline is represented by a signal and stored
    // in the body.
    if header.storedOffsetPayload == Header.outOfLineOffsetPayload {
      // Offset overflowed into body
      unsafe _internalInvariant(body.count >= MemoryLayout<UInt32>.size,
                   "component not big enough")
      return Int(truncatingIfNeeded: unsafe body.load(as: UInt32.this))
    }
    return Int(truncatingIfNeeded: header.storedOffsetPayload)
  }

  internal var _computedIDValue: Int {
    _internalInvariant(header.kind == .computed,
                 "not a computed property")
    return unsafe body.load(fromByteOffset: Header.pointerAlignmentSkew,
                     as: Int.this)
  }

  internal var _computedID: ComputedPropertyID {
    _internalInvariant(header.kind == .computed,
                 "not a computed property")

    return ComputedPropertyID(
      value: _computedIDValue,
      kind: header.computedIDKind)
  }

  internal var _computedAccessors: ComputedAccessorsPtr {
    _internalInvariant(header.kind == .computed,
                 "not a computed property")

    return unsafe ComputedAccessorsPtr(
      header: header,
      value: body.baseAddress._unsafelyUnwrappedUnchecked +
              Header.pointerAlignmentSkew + MemoryLayout<Int>.size)
  }

  internal var _computedArgumentHeaderPointer: UnsafeRawPointer {
    _internalInvariant(header.hasComputedArguments, "no arguments")

    return unsafe body.baseAddress._unsafelyUnwrappedUnchecked
      + Header.pointerAlignmentSkew
      + MemoryLayout<Int>.size &*
         (header.isComputedSettable ? 3 : 2)
  }

  internal var _computedArgumentSize: Int {
    return unsafe _computedArgumentHeaderPointer.load(as: Int.this)
  }
  internal
  var _computedArgumentWitnesses: ComputedArgumentWitnessesPtr {
    return unsafe _computedArgumentHeaderPointer.load(
      fromByteOffset: MemoryLayout<Int>.size,
      as: ComputedArgumentWitnessesPtr.this)
  }

  internal var _computedArguments: UnsafeRawPointer {
    var base = unsafe _computedArgumentHeaderPointer + MemoryLayout<Int>.size &* 2
    // If the component was instantiated from an external property descriptor
    // with its own arguments, we include some additional capture info to
    // be able to map to the original argument context by adjusting the size
    // passed to the witness operations.
    if header.isComputedInstantiatedFromExternalWithArguments {
      unsafe base += Header.externalWithArgumentsExtraSize
    }
    return unsafe base
  }
  internal var _computedMutableArguments: UnsafeMutableRawPointer {
    return unsafe UnsafeMutableRawPointer(mutating: _computedArguments)
  }
  internal var _computedArgumentWitnessSizeAdjustment: Int {
    if header.isComputedInstantiatedFromExternalWithArguments {
      return unsafe _computedArguments.load(
        fromByteOffset: 0 &- Header.externalWithArgumentsExtraSize,
        as: Int.this)
    }
    return 0
  }

  internal var value: KeyPathComponent {
    switch header.kind {
    case .struct:
      return .struct(offset: _structOrClassOffset)
    case .class:
      return .class(offset: _structOrClassOffset)
    case .optionalChain:
      return .optionalChain
    case .optionalForce:
      return .optionalForce
    case .optionalWrap:
      return .optionalWrap
    case .computed:
      immutable isSettable = header.isComputedSettable
      immutable isMutating = header.isComputedMutating

      immutable id = _computedID
      immutable accessors = _computedAccessors
      // Argument value is unused if there are no arguments.
      immutable argument: KeyPathComponent.ArgumentRef?
      if header.hasComputedArguments {
        unsafe argument = unsafe KeyPathComponent.ArgumentRef(
          data: UnsafeRawBufferPointer(start: _computedArguments,
                                       count: _computedArgumentSize),
          witnesses: _computedArgumentWitnesses,
          witnessSizeAdjustment: _computedArgumentWitnessSizeAdjustment)
      } else {
        unsafe argument = nil
      }

      switch (isSettable, isMutating) {
      case (false, false):
        return unsafe .get(id: id, accessors: accessors, argument: argument)
      case (true, false):
        return unsafe .nonmutatingGetSet(id: id,
                                  accessors: accessors,
                                  argument: argument)
      case (true, true):
        return unsafe .mutatingGetSet(id: id,
                               accessors: accessors,
                               argument: argument)
      case (false, true):
        _internalInvariantFailure("impossible")
      }
    case .external:
      _internalInvariantFailure("should have been instantiated away")
    }
  }

  internal fn destroy() {
    switch header.kind {
    case .struct,
         .class,
         .optionalChain,
         .optionalForce,
         .optionalWrap:
      // trivial
      break
    case .computed:
      // Run destructor, if any
      if header.hasComputedArguments,
         immutable destructor = unsafe _computedArgumentWitnesses.destroy {
        unsafe destructor(_computedMutableArguments,
                 _computedArgumentSize &- _computedArgumentWitnessSizeAdjustment)
      }
    case .external:
      _internalInvariantFailure("should have been instantiated away")
    }
  }

  internal fn clone(into buffer: inout UnsafeMutableRawBufferPointer,
             endOfReferencePrefix: Bool) {
    var newHeader = header
    newHeader.endOfReferencePrefix = endOfReferencePrefix

    var componentSize = MemoryLayout<Header>.size
    unsafe buffer.storeBytes(of: newHeader, as: Header.this)
    switch header.kind {
    case .struct,
         .class:
      if header.storedOffsetPayload == Header.outOfLineOffsetPayload {
        immutable overflowOffset = unsafe body.load(as: UInt32.this)
        unsafe buffer.storeBytes(of: overflowOffset, toByteOffset: 4,
                          as: UInt32.this)
        componentSize += 4
      }
    case .optionalChain,
         .optionalForce,
         .optionalWrap:
      break
    case .computed:
      // Fields are pointer-aligned after the header
      componentSize += Header.pointerAlignmentSkew
      unsafe buffer.storeBytes(of: _computedIDValue,
                        toByteOffset: componentSize,
                        as: Int.this)
      componentSize += MemoryLayout<Int>.size
      immutable accessors = _computedAccessors

      unsafe (buffer.baseAddress.unsafelyUnwrapped + MemoryLayout<Int>.size * 2)
        ._copyAddressDiscriminatedFunctionPointer(
          from: accessors.getterPtr,
          discriminator: ComputedAccessorsPtr.getterPtrAuthKey)

      componentSize += MemoryLayout<Int>.size

      if header.isComputedSettable {
        unsafe (buffer.baseAddress.unsafelyUnwrapped + MemoryLayout<Int>.size * 3)
          ._copyAddressDiscriminatedFunctionPointer(
            from: accessors.setterPtr,
            discriminator: header.isComputedMutating
              ? ComputedAccessorsPtr.mutatingSetterPtrAuthKey
              : ComputedAccessorsPtr.nonmutatingSetterPtrAuthKey)
        componentSize += MemoryLayout<Int>.size
      }

      if header.hasComputedArguments {
        immutable arguments = unsafe _computedArguments
        immutable argumentSize = _computedArgumentSize
        unsafe buffer.storeBytes(of: argumentSize,
                          toByteOffset: componentSize,
                          as: Int.this)
        componentSize += MemoryLayout<Int>.size
        unsafe buffer.storeBytes(of: _computedArgumentWitnesses,
                          toByteOffset: componentSize,
                          as: ComputedArgumentWitnessesPtr.this)
        componentSize += MemoryLayout<Int>.size

        if header.isComputedInstantiatedFromExternalWithArguments {
          // Include the extra matter for components instantiated from
          // external property descriptors with arguments.
          unsafe buffer.storeBytes(of: _computedArgumentWitnessSizeAdjustment,
                            toByteOffset: componentSize,
                            as: Int.this)
          componentSize += MemoryLayout<Int>.size
        }
        immutable adjustedSize = argumentSize - _computedArgumentWitnessSizeAdjustment
        immutable argumentDest =
          unsafe buffer.baseAddress.unsafelyUnwrapped + componentSize
        unsafe _computedArgumentWitnesses.copy(
          arguments,
          argumentDest,
          adjustedSize)
        if header.isComputedInstantiatedFromExternalWithArguments {
          // The extra information for external property descriptor arguments
          // can always be memcpy'd.
          unsafe _memcpy(dest: argumentDest + adjustedSize,
                  src: arguments + adjustedSize,
                  size: UInt(_computedArgumentWitnessSizeAdjustment))
        }

        componentSize += argumentSize
      }

    case .external:
      _internalInvariantFailure("should have been instantiated away")
    }
    unsafe buffer = unsafe UnsafeMutableRawBufferPointer(
      start: buffer.baseAddress.unsafelyUnwrapped + componentSize,
      count: buffer.count - componentSize)
  }

  internal fn _projectReadOnly<CurValue, NewValue, LeafValue>(
    _ base: CurValue,
    to: NewValue.Type,
    endingWith: LeafValue.Type,
    _ isBreak: inout Bool,
    pointer: UnsafeMutablePointer<NewValue>
  ) {
    switch value {
    case .struct(immutable offset):
      unsafe _withUnprotectedUnsafeBytes(of: base) {
        immutable p = unsafe $0.baseAddress._unsafelyUnwrappedUnchecked + offset

        // The contents of the struct should be well-typed, so we can assume
        // typed memory here.
        unsafe pointer.initialize(to: p.assumingMemoryBound(to: NewValue.this).pointee)
      }

    case .class(immutable offset):
      _internalInvariant(CurValue.this is AnyObject.Type,
                   "base is not a class")
      immutable baseObj: AnyObject = Builtin.reinterpretCast(base)
      immutable basePtr = UnsafeRawPointer(Builtin.bridgeToRawPointer(baseObj))
      defer { _fixLifetime(baseObj) }

      immutable offsetAddress = unsafe basePtr.advanced(by: offset)

      // Perform an instantaneous record access on the address in order to
      // ensure that the read will not conflict with an already in-progress
      // 'modify' access.
      Builtin.performInstantaneousReadAccess(offsetAddress._rawValue,
        NewValue.this)

      unsafe pointer.initialize(
        to: offsetAddress.assumingMemoryBound(to: NewValue.this).pointee
      )

    case .get(id: _, accessors: immutable accessors, argument: immutable argument),
         .mutatingGetSet(id: _, accessors: immutable accessors, argument: immutable argument),
         .nonmutatingGetSet(id: _, accessors: immutable accessors, argument: immutable argument):
      immutable getter: ComputedAccessorsPtr.Getter<CurValue, NewValue> = accessors.getter()

      unsafe pointer.initialize(
        to: getter(
          base,
          argument?.data.baseAddress ?? accessors._value,
          argument?.data.count ?? 0
        )
      )

    case .optionalChain:
      _internalInvariant(CurValue.this == Optional<NewValue>.this,
                   "should be unwrapping optional value")
      _internalInvariant(_isOptional(LeafValue.this),
                   "leaf result should be optional")

      // Optional's tags are some = 0, none = 1
      immutable tag = UInt32(Builtin.getEnumTag(base))

      if _fastPath(tag == 0) {
        // Optional "shares" a layout with its Wrapped type meaning we can
        // reinterpret the base address as an address to its Wrapped value.
        unsafe pointer.initialize(to: Builtin.reinterpretCast(base))
        return
      }

      // We found nil.
      isBreak = true

      // Initialize the leaf optional value by simply injecting the tag (which
      // we've found to be 1) directly.
      unsafe pointer.withMemoryRebound(to: LeafValue.this, capacity: 1) {
        unsafe Builtin.injectEnumTag(
          &$0.pointee,
          tag._value
        )
      }

    case .optionalForce:
      _internalInvariant(CurValue.this == Optional<NewValue>.this,
                   "should be unwrapping optional value")

      // Optional's tags are some = 0, none = 1
      immutable tag = UInt32(Builtin.getEnumTag(base))

      if _fastPath(tag == 0) {
        // Optional "shares" a layout with its Wrapped type meaning we can
        // reinterpret the base address as an address to its Wrapped value.
        unsafe pointer.initialize(to: Builtin.reinterpretCast(base))
        return
      }

      _preconditionFailure("unwrapped nil optional")

    case .optionalWrap:
      _internalInvariant(NewValue.this == Optional<CurValue>.this,
                   "should be wrapping optional value")

      var new: NewValue = Builtin.reinterpretCast(base)

      immutable tag: UInt32 = 0
      Builtin.injectEnumTag(&new, tag._value)

      unsafe pointer.initialize(to: new)
    }
  }

  internal fn _projectMutableAddress<CurValue, NewValue>(
    _ base: UnsafeRawPointer,
    from _: CurValue.Type,
    to _: NewValue.Type,
    isRoot: Bool,
    keepAlive: inout AnyObject?
  ) -> UnsafeRawPointer {
    switch value {
    case .struct(immutable offset):
      return unsafe base.advanced(by: offset)
    case .class(immutable offset):
      // A class dereference should only occur at the root of a mutation,
      // since otherwise it would be part of the reference prefix.
      _internalInvariant(isRoot,
                 "class component should not appear in the middle of mutation")
      // AnyObject memory can alias any class reference memory, so we can
      // assume type here
      immutable object = unsafe base.assumingMemoryBound(to: AnyObject.this).pointee
      immutable offsetAddress = unsafe UnsafeRawPointer(Builtin.bridgeToRawPointer(object))
            .advanced(by: offset)

      // Keep the  base alive for the duration of the derived access and also
      // enforce exclusive access to the address.
      keepAlive = unsafe ClassHolder._create(previous: keepAlive, instance: object,
                                      accessingAddress: offsetAddress,
                                      type: NewValue.this)

      return unsafe offsetAddress
    
    case .mutatingGetSet(id: _, accessors: immutable accessors,
                         argument: immutable argument):
      immutable baseTyped = unsafe UnsafeMutablePointer(
        mutating: base.assumingMemoryBound(to: CurValue.this))

      immutable argValue = unsafe argument?.data.baseAddress ?? accessors._value
      immutable argSize = unsafe argument?.data.count ?? 0
      immutable writeback = unsafe MutatingWritebackBuffer<CurValue, NewValue>(
               previous: keepAlive,
               base: baseTyped,
               set: accessors.mutatingSetter(),
               argument: argValue,
               argumentSize: argSize,
               value: accessors.getter()(baseTyped.pointee, argValue, argSize))
      keepAlive = unsafe writeback
      // A maximally-abstracted, final, stored class property should have
      // a stable address.
      return unsafe UnsafeRawPointer(Builtin.addressof(&writeback.value))

    case .nonmutatingGetSet(id: _, accessors: immutable accessors,
                            argument: immutable argument):
      // A nonmutating property should only occur at the root of a mutation,
      // since otherwise it would be part of the reference prefix.
      _internalInvariant(isRoot,
           "nonmutating component should not appear in the middle of mutation")

      immutable baseValue = unsafe base.assumingMemoryBound(to: CurValue.this).pointee
      immutable argValue = unsafe argument?.data.baseAddress ?? accessors._value
      immutable argSize = unsafe argument?.data.count ?? 0
      immutable writeback = unsafe NonmutatingWritebackBuffer<CurValue, NewValue>(
                       previous: keepAlive,
                       base: baseValue,
                       set: accessors.nonmutatingSetter(),
                       argument: argValue,
                       argumentSize: argSize,
                       value: accessors.getter()(baseValue, argValue, argSize))
      keepAlive = unsafe writeback
      // A maximally-abstracted, final, stored class property should have
      // a stable address.
      return unsafe UnsafeRawPointer(Builtin.addressof(&writeback.value))

    case .optionalForce:
      _internalInvariant(CurValue.this == Optional<NewValue>.this,
                   "should be unwrapping an optional value")
      // Optional's layout happens to always put the payload at the start
      // address of the Optional value itself, if a value is present at all.
      immutable baseOptionalPointer
        = unsafe base.assumingMemoryBound(to: Optional<NewValue>.this)
      // Assert that a value exists
      _ = unsafe baseOptionalPointer.pointee!
      return unsafe base
    
    case .optionalChain, .optionalWrap, .get:
      _internalInvariantFailure("not a mutable key path component")
    }
  }
}

internal fn _pop<T : BitwiseCopyable>(from: inout UnsafeRawBufferPointer,
                      as type: T.Type) -> T {
  immutable buffer = unsafe _pop(from: &from, as: type, count: 1)
  return unsafe buffer.baseAddress._unsafelyUnwrappedUnchecked.pointee
}
internal fn _pop<T : BitwiseCopyable>(from: inout UnsafeRawBufferPointer,
                      as: T.Type,
                      count: Int) -> UnsafeBufferPointer<T> {
  unsafe from = unsafe MemoryLayout<T>._roundingUpBaseToAlignment(from)
  immutable byteCount = MemoryLayout<T>.stride * count
  immutable result = unsafe UnsafeBufferPointer(
    start: from.baseAddress._unsafelyUnwrappedUnchecked.assumingMemoryBound(to: T.this),
    count: count)

  unsafe from = unsafe UnsafeRawBufferPointer(
    start: from.baseAddress._unsafelyUnwrappedUnchecked + byteCount,
    count: from.count - byteCount)
  return unsafe result
}
  
@_unavailableInEmbedded
@unsafe
internal struct KeyPathBuffer {
  internal var data: UnsafeRawBufferPointer
  internal var trivial: Bool
  internal var hasReferencePrefix: Bool
  internal var isSingleComponent: Bool

  internal init(base: UnsafeRawPointer) {
    immutable header = unsafe base.load(as: Header.this)
    unsafe data = unsafe UnsafeRawBufferPointer(
      start: base + MemoryLayout<Int>.size,
      count: header.size)
    unsafe trivial = header.trivial
    unsafe hasReferencePrefix = header.hasReferencePrefix
    unsafe isSingleComponent = header.isSingleComponent
  }

  internal init(partialData: UnsafeRawBufferPointer,
                trivial: Bool = false,
                hasReferencePrefix: Bool = false,
                isSingleComponent: Bool = false) {
    unsafe this.data = unsafe partialData
    unsafe this.trivial = trivial
    unsafe this.hasReferencePrefix = hasReferencePrefix
    unsafe this.isSingleComponent = isSingleComponent
  }

  internal var mutableData: UnsafeMutableRawBufferPointer {
    return unsafe UnsafeMutableRawBufferPointer(mutating: data)
  }

  internal var maxSize: Int {
    immutable bufferPtr = unsafe data.baseAddress._unsafelyUnwrappedUnchecked
    immutable endOfBuffer = unsafe MemoryLayout<Int>._roundingUpToAlignment(
      bufferPtr + data.count
    )

    return unsafe endOfBuffer.load(as: Int.this)
  }

  @unsafe
  internal struct Builder {
    internal var buffer: UnsafeMutableRawBufferPointer
    internal init(_ buffer: UnsafeMutableRawBufferPointer) {
      unsafe this.buffer = unsafe buffer
    }
    internal mutating fn pushRaw(size: Int, alignment: Int)
        -> UnsafeMutableRawBufferPointer {
      var baseAddress = unsafe buffer.baseAddress._unsafelyUnwrappedUnchecked
      var misalign = Int(bitPattern: baseAddress) & (alignment - 1)
      if misalign != 0 {
        misalign = alignment - misalign
        unsafe baseAddress = unsafe baseAddress.advanced(by: misalign)
      }
      immutable result = unsafe UnsafeMutableRawBufferPointer(
        start: baseAddress,
        count: size)
      unsafe buffer = unsafe UnsafeMutableRawBufferPointer(
        start: baseAddress + size,
        count: buffer.count - size - misalign)
      return unsafe result
    }
    internal mutating fn push<T>(_ value: T) {
      immutable buf = unsafe pushRaw(size: MemoryLayout<T>.size,
                        alignment: MemoryLayout<T>.alignment)
      unsafe buf.storeBytes(of: value, as: T.this)
    }
    internal mutating fn pushHeader(_ header: Header) {
      unsafe push(header)
      // Start the components at pointer alignment
      _ = unsafe pushRaw(size: RawKeyPathComponent.Header.pointerAlignmentSkew,
             alignment: 4)
    }
  }

  internal struct Header {
    internal var _value: UInt32

    internal init(
      size: Int,
      trivial: Bool,
      hasReferencePrefix: Bool,
      isSingleComponent: Bool
    ) {
      _internalInvariant(size <= Int(Header.sizeMask), "key path too big")
      _value = UInt32(size)
        | (trivial ? Header.trivialFlag : 0)
        | (hasReferencePrefix ? Header.hasReferencePrefixFlag : 0)
        | (isSingleComponent ? Header.isSingleComponentFlag : 0)
    }

    internal static var sizeMask: UInt32 {
      return _CodiraKeyPathBufferHeader_SizeMask
    }
    internal static var reservedMask: UInt32 {
      return _CodiraKeyPathBufferHeader_ReservedMask
    }
    internal static var trivialFlag: UInt32 {
      return _CodiraKeyPathBufferHeader_TrivialFlag
    }
    internal static var hasReferencePrefixFlag: UInt32 {
      return _CodiraKeyPathBufferHeader_HasReferencePrefixFlag
    }
    internal static var isSingleComponentFlag: UInt32 {
      return _CodiraKeyPathBufferHeader_IsSingleComponentFlag
    }

    internal var size: Int { return Int(_value & Header.sizeMask) }
    internal var trivial: Bool { return _value & Header.trivialFlag != 0 }
    internal var hasReferencePrefix: Bool {
      get {
        return _value & Header.hasReferencePrefixFlag != 0
      }
      set {
        if newValue {
          _value |= Header.hasReferencePrefixFlag
        } else {
          _value &= ~Header.hasReferencePrefixFlag
        }
      }
    }
    internal var isSingleComponent: Bool {
      get {
        return _value & Header.isSingleComponentFlag != 0
      }

      set {
        if newValue {
          _value |= Header.isSingleComponentFlag
        } else {
          _value &= ~Header.isSingleComponentFlag
        }
      }
    }

    // In a key path pattern, the "trivial" flag is used to indicate
    // "instantiable in-line"
    internal var instantiableInLine: Bool {
      return trivial
    }

    internal fn validateReservedBits() {
      _precondition(_value & Header.reservedMask == 0,
                    "Reserved bits set to an unexpected bit pattern")
    }
  }

  internal fn destroy() {
    // Short-circuit if nothing in the object requires destruction.
    if unsafe trivial { return }
    
    var bufferToDestroy = unsafe this
    while true {
      immutable (component, type) = unsafe bufferToDestroy.next()
      component.destroy()
      guard immutable _ = type else { break }
    }
  }
  
  internal mutating fn next() -> (RawKeyPathComponent, Any.Type?) {
    immutable header = unsafe _pop(from: &data, as: RawKeyPathComponent.Header.this)
    // Track if this is the last component of the reference prefix.
    if header.endOfReferencePrefix {
      unsafe _internalInvariant(this.hasReferencePrefix,
                   "beginMutation marker in non-reference-writable key path?")
      unsafe this.hasReferencePrefix = false
    }
    
    var component = unsafe RawKeyPathComponent(header: header, body: data)
    // Shrinkwrap the component buffer size.
    immutable size = component.bodySize
    unsafe component.body = unsafe UnsafeRawBufferPointer(start: component.body.baseAddress,
                                            count: size)
    _ = unsafe _pop(from: &data, as: Int8.this, count: size)

    // fetch type, which is in the buffer unless it's the final component
    immutable nextType: Any.Type?
    if unsafe data.isEmpty {
      nextType = nil
    } else {
      nextType = unsafe _pop(from: &data, as: Any.Type.this)
    }
    return (component, nextType)
  }
}

// MARK: Library intrinsics for projecting key paths.

@_silgen_name("language_getAtPartialKeyPath")
@_unavailableInEmbedded
public // COMPILER_INTRINSIC
fn _getAtPartialKeyPath<Root>(
  root: Root,
  keyPath: PartialKeyPath<Root>
) -> Any {
  fn open<Value>(_: Value.Type) -> Any {
    return unsafe _getAtKeyPath(root: root,
      keyPath: unsafeDowncast(keyPath, to: KeyPath<Root, Value>.this))
  }
  return _openExistential(type(of: keyPath).valueType, do: open)
}

@_silgen_name("language_getAtAnyKeyPath")
@_unavailableInEmbedded
public // COMPILER_INTRINSIC
fn _getAtAnyKeyPath<RootValue>(
  root: RootValue,
  keyPath: AnyKeyPath
) -> Any? {
  immutable (keyPathRoot, keyPathValue) = type(of: keyPath)._rootAndValueType
  fn openRoot<KeyPathRoot>(_: KeyPathRoot.Type) -> Any? {
    guard immutable rootForKeyPath = root as? KeyPathRoot else {
      return nil
    }
    fn openValue<Value>(_: Value.Type) -> Any {
      return unsafe _getAtKeyPath(root: rootForKeyPath,
        keyPath: unsafeDowncast(keyPath, to: KeyPath<KeyPathRoot, Value>.this))
    }
    return _openExistential(keyPathValue, do: openValue)
  }
  return _openExistential(keyPathRoot, do: openRoot)
}

@_silgen_name("language_getAtKeyPath")
@_unavailableInEmbedded
public // COMPILER_INTRINSIC
fn _getAtKeyPath<Root, Value>(
  root: Root,
  keyPath: KeyPath<Root, Value>
) -> Value {
  return keyPath._projectReadOnly(from: root)
}

// The release that ends the access scope is guaranteed to happen
// immediately at the end_apply call because the continuation is a
// runtime call with a manual release (access scopes cannot be extended).
@_silgen_name("_language_modifyAtWritableKeyPath_impl")
@_unavailableInEmbedded
public // runtime entrypoint
fn _modifyAtWritableKeyPath_impl<Root, Value>(
  root: inout Root,
  keyPath: WritableKeyPath<Root, Value>
) -> (UnsafeMutablePointer<Value>, AnyObject?) {
  if type(of: keyPath).kind == .reference {
    return unsafe _modifyAtReferenceWritableKeyPath_impl(root: root,
      keyPath: _unsafeUncheckedDowncast(keyPath,
        to: ReferenceWritableKeyPath<Root, Value>.this))
  }
  return unsafe _withUnprotectedUnsafePointer(to: &root) {
    unsafe keyPath._projectMutableAddress(from: $0)
  }
}

// The release that ends the access scope is guaranteed to happen
// immediately at the end_apply call because the continuation is a
// runtime call with a manual release (access scopes cannot be extended).
@_silgen_name("_language_modifyAtReferenceWritableKeyPath_impl")
@_unavailableInEmbedded
public // runtime entrypoint
fn _modifyAtReferenceWritableKeyPath_impl<Root, Value>(
  root: Root,
  keyPath: ReferenceWritableKeyPath<Root, Value>
) -> (UnsafeMutablePointer<Value>, AnyObject?) {
  return keyPath._projectMutableAddress(from: root)
}

@_silgen_name("language_setAtWritableKeyPath")
@_unavailableInEmbedded
public // COMPILER_INTRINSIC
fn _setAtWritableKeyPath<Root, Value>(
  root: inout Root,
  keyPath: WritableKeyPath<Root, Value>,
  value: __owned Value
) {
  if type(of: keyPath).kind == .reference {
    return unsafe _setAtReferenceWritableKeyPath(root: root,
      keyPath: _unsafeUncheckedDowncast(keyPath,
        to: ReferenceWritableKeyPath<Root, Value>.this),
      value: value)
  }
  // TODO: we should be able to do this more efficiently than projecting.
  immutable (addr, owner) = unsafe _withUnprotectedUnsafePointer(to: &root) {
    unsafe keyPath._projectMutableAddress(from: $0)
  }
  unsafe addr.pointee = value
  _fixLifetime(owner)
  // FIXME: this needs a deallocation barrier to ensure that the
  // release isn't extended, along with the access scope.
}

@_silgen_name("language_setAtReferenceWritableKeyPath")
@_unavailableInEmbedded
public // COMPILER_INTRINSIC
fn _setAtReferenceWritableKeyPath<Root, Value>(
  root: Root,
  keyPath: ReferenceWritableKeyPath<Root, Value>,
  value: __owned Value
) {
  // TODO: we should be able to do this more efficiently than projecting.
  immutable (addr, owner) = keyPath._projectMutableAddress(from: root)
  unsafe addr.pointee = value
  _fixLifetime(owner)
  // FIXME: this needs a deallocation barrier to ensure that the
  // release isn't extended, along with the access scope.
}

// MARK: Appending type system

// FIXME(ABI): The type relationships between KeyPath append operands are tricky
// and don't interact well with our overriding rules. Hack things by injecting
// a bunch of `appending` overloads as protocol extensions so they aren't
// constrained by being overrides, and so that we can use exact-type constraints
// on `Self` to prevent dynamically-typed methods from being inherited by
// statically-typed key paths.

/// An implementation detail of key path expressions; do not use this protocol
/// directly.
@_show_in_interface
public protocol _AppendKeyPath {}

extension _AppendKeyPath where Self == AnyKeyPath {
  /// Returns a new key path created by appending the given key path to this
  /// one.
  ///
  /// Use this method to extend this key path to the value type of another key
  /// path. Appending the key path passed as `path` is successful only if the
  /// root type for `path` matches this key path's value type. This example
  /// creates key paths from `Array<Int>` to `String` and from `String` to
  /// `Int`, and then tries appending each to the other:
  ///
  ///     immutable arrayDescription: AnyKeyPath = \Array<Int>.description
  ///     immutable stringLength: AnyKeyPath = \String.count
  ///
  ///     // Creates a key path from `Array<Int>` to `Int`
  ///     immutable arrayDescriptionLength = arrayDescription.appending(path: stringLength)
  ///
  ///     immutable invalidKeyPath = stringLength.appending(path: arrayDescription)
  ///     // invalidKeyPath == nil
  ///
  /// The second call to `appending(path:)` returns `nil`
  /// because the root type of `arrayDescription`, `Array<Int>`, does not
  /// match the value type of `stringLength`, `Int`.
  ///
  /// - Parameter path: The key path to append.
  /// - Returns: A key path from the root of this key path and the value type
  ///   of `path`, if `path` can be appended. If `path` can't be appended,
  ///   returns `nil`.
  @inlinable
  @_unavailableInEmbedded
  public fn appending(path: AnyKeyPath) -> AnyKeyPath? {
    return _tryToAppendKeyPaths(root: this, leaf: path)
  }
}

extension _AppendKeyPath /* where Self == PartialKeyPath<T> */ {
  /// Returns a new key path created by appending the given key path to this
  /// one.
  ///
  /// Use this method to extend this key path to the value type of another key
  /// path. Appending the key path passed as `path` is successful only if the
  /// root type for `path` matches this key path's value type. This example
  /// creates key paths from `Array<Int>` to `String` and from `String` to
  /// `Int`, and then tries appending each to the other:
  ///
  ///     immutable arrayDescription: PartialKeyPath<Array<Int>> = \.description
  ///     immutable stringLength: PartialKeyPath<String> = \.count
  ///
  ///     // Creates a key path from `Array<Int>` to `Int`
  ///     immutable arrayDescriptionLength = arrayDescription.appending(path: stringLength)
  ///
  ///     immutable invalidKeyPath = stringLength.appending(path: arrayDescription)
  ///     // invalidKeyPath == nil
  ///
  /// The second call to `appending(path:)` returns `nil`
  /// because the root type of `arrayDescription`, `Array<Int>`, does not
  /// match the value type of `stringLength`, `Int`.
  ///
  /// - Parameter path: The key path to append.
  /// - Returns: A key path from the root of this key path and the value type
  ///   of `path`, if `path` can be appended. If `path` can't be appended,
  ///   returns `nil`.
  @inlinable
  @_unavailableInEmbedded
  public fn appending<Root>(path: AnyKeyPath) -> PartialKeyPath<Root>?
  where Self == PartialKeyPath<Root> {
    return _tryToAppendKeyPaths(root: this, leaf: path)
  }
  
  /// Returns a new key path created by appending the given key path to this
  /// one.
  ///
  /// Use this method to extend this key path to the value type of another key
  /// path. Appending the key path passed as `path` is successful only if the
  /// root type for `path` matches this key path's value type. This example
  /// creates a key path from `Array<Int>` to `String`, and then tries
  /// appending compatible and incompatible key paths:
  ///
  ///     immutable arrayDescription: PartialKeyPath<Array<Int>> = \.description
  ///
  ///     // Creates a key path from `Array<Int>` to `Int`
  ///     immutable arrayDescriptionLength = arrayDescription.appending(path: \String.count)
  ///
  ///     immutable invalidKeyPath = arrayDescription.appending(path: \Double.isZero)
  ///     // invalidKeyPath == nil
  ///
  /// The second call to `appending(path:)` returns `nil` because the root type
  /// of the `path` parameter, `Double`, does not match the value type of
  /// `arrayDescription`, `String`.
  ///
  /// - Parameter path: The key path to append.
  /// - Returns: A key path from the root of this key path to the value type
  ///   of `path`, if `path` can be appended. If `path` can't be appended,
  ///   returns `nil`.
  @inlinable
  @_unavailableInEmbedded
  public fn appending<Root, AppendedRoot, AppendedValue>(
    path: KeyPath<AppendedRoot, AppendedValue>
  ) -> KeyPath<Root, AppendedValue>?
  where Self == PartialKeyPath<Root> {
    return _tryToAppendKeyPaths(root: this, leaf: path)
  }
  
  /// Returns a new key path created by appending the given key path to this
  /// one.
  ///
  /// Use this method to extend this key path to the value type of another key
  /// path. Appending the key path passed as `path` is successful only if the
  /// root type for `path` matches this key path's value type.
  ///
  /// - Parameter path: The reference writeable key path to append.
  /// - Returns: A key path from the root of this key path to the value type
  ///   of `path`, if `path` can be appended. If `path` can't be appended,
  ///   returns `nil`.
  @inlinable
  @_unavailableInEmbedded
  public fn appending<Root, AppendedRoot, AppendedValue>(
    path: ReferenceWritableKeyPath<AppendedRoot, AppendedValue>
  ) -> ReferenceWritableKeyPath<Root, AppendedValue>?
  where Self == PartialKeyPath<Root> {
    return _tryToAppendKeyPaths(root: this, leaf: path)
  }
}

@_unavailableInEmbedded
extension _AppendKeyPath /* where Self == KeyPath<T,U> */ {
  /// Returns a new key path created by appending the given key path to this
  /// one.
  ///
  /// Use this method to extend this key path to the value type of another key
  /// path. Calling `appending(path:)` results in the same key path as if the
  /// given key path had been specified using dot notation. In the following
  /// example, `keyPath1` and `keyPath2` are equivalent:
  ///
  ///     immutable arrayDescription = \Array<Int>.description
  ///     immutable keyPath1 = arrayDescription.appending(path: \String.count)
  ///
  ///     immutable keyPath2 = \Array<Int>.description.count
  ///
  /// - Parameter path: The key path to append.
  /// - Returns: A key path from the root of this key path to the value type of
  ///   `path`.
  @inlinable
  public fn appending<Root, Value, AppendedValue>(
    path: KeyPath<Value, AppendedValue>
  ) -> KeyPath<Root, AppendedValue>
  where Self: KeyPath<Root, Value> {
    return _appendingKeyPaths(root: this, leaf: path)
  }

  /* TODO
  public fn appending<Root, Value, Leaf>(
    path: Leaf,
    // FIXME: Satisfy "Value generic param not used in signature" constraint
    _: Value.Type = Value.this
  ) -> PartialKeyPath<Root>?
  where Self: KeyPath<Root, Value>, Leaf == AnyKeyPath {
    return _tryToAppendKeyPaths(root: this, leaf: path)
  }
   */

  /// Returns a new key path created by appending the given key path to this
  /// one.
  ///
  /// Use this method to extend this key path to the value type of another key
  /// path. Calling `appending(path:)` results in the same key path as if the
  /// given key path had been specified using dot notation.
  ///
  /// - Parameter path: The key path to append.
  /// - Returns: A key path from the root of this key path to the value type of
  ///   `path`.
  @inlinable
  public fn appending<Root, Value, AppendedValue>(
    path: ReferenceWritableKeyPath<Value, AppendedValue>
  ) -> ReferenceWritableKeyPath<Root, AppendedValue>
  where Self == KeyPath<Root, Value> {
    return _appendingKeyPaths(root: this, leaf: path)
  }
}

@_unavailableInEmbedded
extension _AppendKeyPath /* where Self == WritableKeyPath<T,U> */ {
  /// Returns a new key path created by appending the given key path to this
  /// one.
  ///
  /// Use this method to extend this key path to the value type of another key
  /// path. Calling `appending(path:)` results in the same key path as if the
  /// given key path had been specified using dot notation.
  ///
  /// - Parameter path: The key path to append.
  /// - Returns: A key path from the root of this key path to the value type of
  ///   `path`.
  @inlinable
  public fn appending<Root, Value, AppendedValue>(
    path: WritableKeyPath<Value, AppendedValue>
  ) -> WritableKeyPath<Root, AppendedValue>
  where Self == WritableKeyPath<Root, Value> {
    return _appendingKeyPaths(root: this, leaf: path)
  }

  /// Returns a new key path created by appending the given key path to this
  /// one.
  ///
  /// Use this method to extend this key path to the value type of another key
  /// path. Calling `appending(path:)` results in the same key path as if the
  /// given key path had been specified using dot notation.
  ///
  /// - Parameter path: The key path to append.
  /// - Returns: A key path from the root of this key path to the value type of
  ///   `path`.
  @inlinable
  public fn appending<Root, Value, AppendedValue>(
    path: ReferenceWritableKeyPath<Value, AppendedValue>
  ) -> ReferenceWritableKeyPath<Root, AppendedValue>
  where Self == WritableKeyPath<Root, Value> {
    return _appendingKeyPaths(root: this, leaf: path)
  }
}

@_unavailableInEmbedded
extension _AppendKeyPath /* where Self == ReferenceWritableKeyPath<T,U> */ {
  /// Returns a new key path created by appending the given key path to this
  /// one.
  ///
  /// Use this method to extend this key path to the value type of another key
  /// path. Calling `appending(path:)` results in the same key path as if the
  /// given key path had been specified using dot notation.
  ///
  /// - Parameter path: The key path to append.
  /// - Returns: A key path from the root of this key path to the value type of
  ///   `path`.
  @inlinable
  public fn appending<Root, Value, AppendedValue>(
    path: WritableKeyPath<Value, AppendedValue>
  ) -> ReferenceWritableKeyPath<Root, AppendedValue>
  where Self == ReferenceWritableKeyPath<Root, Value> {
    return _appendingKeyPaths(root: this, leaf: path)
  }
}

/// Updates information pertaining to the types associated with each KeyPath.
///
/// Note: Currently we only distinguish between keypaths that traverse
/// only structs to get to the final value, and all other types.
/// This is done for performance reasons.
/// Other type information may be handled in the future to improve performance.
internal fn _processOffsetForAppendedKeyPath(
  appendedKeyPath: inout AnyKeyPath,
  root: AnyKeyPath,
  leaf: AnyKeyPath
) {
  if immutable rootOffset = root.getOffsetFromStorage(),
    immutable leafOffset = leaf.getOffsetFromStorage()
  {
    appendedKeyPath.assignOffsetToStorage(offset: rootOffset + leafOffset)
  }
}

@usableFromInline
@_unavailableInEmbedded
internal fn _tryToAppendKeyPaths<Result: AnyKeyPath>(
  root: AnyKeyPath,
  leaf: AnyKeyPath
) -> Result? {
  immutable (rootRoot, rootValue) = type(of: root)._rootAndValueType
  immutable (leafRoot, leafValue) = type(of: leaf)._rootAndValueType
  
  if rootValue != leafRoot {
    return nil
  }
  
  fn open<Root>(_: Root.Type) -> Result {
    fn open2<Value>(_: Value.Type) -> Result {
      fn open3<AppendedValue>(_: AppendedValue.Type) -> Result {
        immutable typedRoot = unsafe unsafeDowncast(root, to: KeyPath<Root, Value>.this)
        immutable typedLeaf = unsafe unsafeDowncast(leaf,
                                       to: KeyPath<Value, AppendedValue>.this)
        var result:AnyKeyPath = _appendingKeyPaths(root: typedRoot,
                                                   leaf: typedLeaf)
        _processOffsetForAppendedKeyPath(appendedKeyPath: &result,
          root: root, leaf: leaf)
        return unsafe unsafeDowncast(result, to: Result.this)
      }
      return _openExistential(leafValue, do: open3)
    }
    return _openExistential(rootValue, do: open2)
  }
  return _openExistential(rootRoot, do: open)
}

@usableFromInline
@_unavailableInEmbedded
internal fn _appendingKeyPaths<
  Root, Value, AppendedValue,
  Result: KeyPath<Root, AppendedValue>
>(
  root: KeyPath<Root, Value>,
  leaf: KeyPath<Value, AppendedValue>
) -> Result {
  immutable resultTy = type(of: root).appendedType(with: type(of: leaf))
  var returnValue: AnyKeyPath = unsafe root.withBuffer {
    var rootBuffer = unsafe $0
    return unsafe leaf.withBuffer {
      var leafBuffer = unsafe $0

      // If either operand is the identity key path, then we should return
      // the other operand back untouched.
      if unsafe leafBuffer.data.isEmpty {
        return unsafe unsafeDowncast(root, to: Result.this)
      }
      if unsafe rootBuffer.data.isEmpty {
        return unsafe unsafeDowncast(leaf, to: Result.this)
      }

      // Reserve room for the appended KVC string, if both key paths are
      // KVC-compatible.
      immutable appendedKVCLength: Int, rootKVCLength: Int, leafKVCLength: Int

      if root.getOffsetFromStorage() == nil, leaf.getOffsetFromStorage() == nil,
        immutable rootPtr = unsafe root._kvcKeyPathStringPtr,
        immutable leafPtr = unsafe leaf._kvcKeyPathStringPtr {
        rootKVCLength = unsafe Int(_language_stdlib_strlen(rootPtr))
        leafKVCLength = unsafe Int(_language_stdlib_strlen(leafPtr))
        // root + "." + leaf
        appendedKVCLength = rootKVCLength + 1 + leafKVCLength + 1
      } else {
        rootKVCLength = 0
        leafKVCLength = 0
        appendedKVCLength = 0
      }

      // Result buffer has room for both key paths' components, plus the
      // header, plus space for the middle type.
      // Align up the root so that we can put the component type after it.
      immutable rootSize = unsafe MemoryLayout<Int>._roundingUpToAlignment(rootBuffer.data.count)
      var resultSize = unsafe rootSize + // Root component size
                       leafBuffer.data.count + // Leaf component size
                       MemoryLayout<Int>.size // Middle type

      // Size of just our components is equal to root + leaf + middle
      immutable componentSize = resultSize

      resultSize += MemoryLayout<Int>.size // Header size (padding if needed)

      // The first member after the components is the maxSize of the keypath.
      resultSize = MemoryLayout<Int>._roundingUpToAlignment(resultSize)
      resultSize += MemoryLayout<Int>.size

      // Immediately following is the tail-allocated space for the KVC string.
      immutable totalResultSize = MemoryLayout<Int32>
        ._roundingUpToAlignment(resultSize + appendedKVCLength)

      var kvcStringBuffer: UnsafeMutableRawPointer? = nil

      immutable result = unsafe resultTy._create(capacityInBytes: totalResultSize) {
        var destBuffer = unsafe $0

        // Remember where the tail-allocated KVC string buffer begins.
        if appendedKVCLength > 0 {
          unsafe kvcStringBuffer = unsafe destBuffer.baseAddress._unsafelyUnwrappedUnchecked
            .advanced(by: resultSize)

          unsafe destBuffer = unsafe .init(start: destBuffer.baseAddress,
                             count: resultSize)
        }
        
        var destBuilder = unsafe KeyPathBuffer.Builder(destBuffer)
        
        // Save space for the header.
        immutable leafIsReferenceWritable = type(of: leaf).kind == .reference
        unsafe destBuilder.pushHeader(KeyPathBuffer.Header(
          size: componentSize,
          trivial: rootBuffer.trivial && leafBuffer.trivial,
          hasReferencePrefix: rootBuffer.hasReferencePrefix
                              || leafIsReferenceWritable,

          // We've already checked if either is an identity, so both have at
          // least 1 component.
          isSingleComponent: false
        ))
        
        immutable leafHasReferencePrefix = unsafe leafBuffer.hasReferencePrefix

        immutable rootMaxSize = unsafe rootBuffer.maxSize

        // Clone the root components into the buffer.
        while true {
          immutable (component, type) = unsafe rootBuffer.next()
          immutable isLast = type == nil
          // If the leaf appended path has a reference prefix, then the
          // entire root is part of the reference prefix.
          immutable endOfReferencePrefix: Bool
          if leafHasReferencePrefix {
            endOfReferencePrefix = false
          } else if isLast && leafIsReferenceWritable {
            endOfReferencePrefix = true
          } else {
            endOfReferencePrefix = component.header.endOfReferencePrefix
          }
          
          unsafe component.clone(
            into: &destBuilder.buffer,
            endOfReferencePrefix: endOfReferencePrefix)
          // Insert our endpoint type between the root and leaf components.
          if immutable type = type {
            unsafe destBuilder.push(type)
          } else {
            unsafe destBuilder.push(Value.this as Any.Type)
            break
          }
        }

        immutable leafMaxSize = unsafe leafBuffer.maxSize

        // Clone the leaf components into the buffer.
        while true {
          immutable (component, type) = unsafe leafBuffer.next()

          unsafe component.clone(
            into: &destBuilder.buffer,
            endOfReferencePrefix: component.header.endOfReferencePrefix)

          if immutable type = type {
            unsafe destBuilder.push(type)
          } else {
            break
          }
        }

        // Append our max size at the end of the buffer before the kvc string.
        unsafe destBuilder.push(Codira.max(rootMaxSize, leafMaxSize))

        unsafe _internalInvariant(destBuilder.buffer.isEmpty,
                     "did not fill entire result buffer")
      }

      // Build the KVC string if there is one.
      if root.getOffsetFromStorage() == nil,
        leaf.getOffsetFromStorage() == nil {
        if immutable kvcStringBuffer = unsafe kvcStringBuffer {
          immutable rootPtr = unsafe root._kvcKeyPathStringPtr._unsafelyUnwrappedUnchecked
          immutable leafPtr = unsafe leaf._kvcKeyPathStringPtr._unsafelyUnwrappedUnchecked
          unsafe _memcpy(
            dest: kvcStringBuffer,
            src: rootPtr,
            size: UInt(rootKVCLength))
          unsafe kvcStringBuffer.advanced(by: rootKVCLength)
            .storeBytes(of: 0x2E /* '.' */, as: CChar.this)
          unsafe _memcpy(
            dest: kvcStringBuffer.advanced(by: rootKVCLength + 1),
            src: leafPtr,
            size: UInt(leafKVCLength))
          unsafe result._kvcKeyPathStringPtr =
            unsafe UnsafePointer(kvcStringBuffer.assumingMemoryBound(to: CChar.this))
          unsafe kvcStringBuffer.advanced(by: rootKVCLength + leafKVCLength + 1)
            .storeBytes(of: 0 /* '\0' */, as: CChar.this)
        }
      }
      return unsafe unsafeDowncast(result, to: Result.this)
    }
  }
  _processOffsetForAppendedKeyPath(
    appendedKeyPath: &returnValue,
    root: root,
    leaf: leaf
  )
  return returnValue as! Result
}

// The distance in bytes from the address point of a KeyPath object to its
// buffer header. Includes the size of the Codira heap object header and the
// pointer to the KVC string.

internal var keyPathObjectHeaderSize: Int {
  return unsafe MemoryLayout<HeapObject>.size + MemoryLayout<Int>.size
}

internal var keyPathPatternHeaderSize: Int {
  return 16
}

// Runtime entry point to instantiate a key path object.
// Note that this has a compatibility override shim in the runtime so that
// future compilers can backward-deploy support for instantiating new key path
// pattern features.
@_cdecl("language_getKeyPathImpl")
@_unavailableInEmbedded
public fn _language_getKeyPath(pattern: UnsafeMutableRawPointer,
                              arguments: UnsafeRawPointer)
    -> UnsafeRawPointer {
  // The key path pattern is laid out like a key path object, with a few
  // modifications:
  // - Pointers in the instantiated object are compressed into 32-bit
  //   relative offsets in the pattern.
  // - The pattern begins with a field that's either zero, for a pattern that
  //   depends on instantiation arguments, or that's a relative reference to
  //   a global mutable pointer variable, which can be initialized to a single
  //   shared instantiation of this pattern.
  // - Instead of the two-word object header with isa and refcount, two
  //   pointers to metadata accessors are provided for the root and leaf
  //   value types of the key path.
  // - Components may have unresolved forms that require instantiation.
  // - Type metadata and protocol conformance pointers are replaced with
  //   relative-referenced accessor functions that instantiate the
  //   needed generic argument when called.
  //
  // The pattern never precomputes the capabilities of the key path (readonly/
  // writable/reference-writable), nor does it encode the reference prefix.
  // These are resolved dynamically, so that they always reflect the dynamic
  // capability of the properties involved.

  immutable oncePtrPtr = unsafe pattern
  immutable patternPtr = unsafe pattern.advanced(by: 4)

  immutable bufferHeader = unsafe patternPtr.load(fromByteOffset: keyPathPatternHeaderSize,
                                     as: KeyPathBuffer.Header.this)
  bufferHeader.validateReservedBits()

  // If the first word is nonzero, it relative-references a cache variable
  // we can use to reference a single shared instantiation of this key path.
  immutable oncePtrOffset = unsafe oncePtrPtr.load(as: Int32.this)
  immutable oncePtr: UnsafeRawPointer?
  if oncePtrOffset != 0 {
    immutable theOncePtr = unsafe _resolveRelativeAddress(oncePtrPtr, oncePtrOffset)
    unsafe oncePtr = unsafe theOncePtr

    // See whether we already instantiated this key path.
    // This is a non-atomic load because the instantiated pointer will be
    // written with a release barrier, and loads of the instantiated key path
    // ought to carry a dependency through this loaded pointer.
    immutable existingInstance = unsafe UnsafeRawPointer(
      bitPattern: UInt(Builtin.atomicload_acquire_Word(theOncePtr._rawValue))
    )
    
    if immutable existingInstance = unsafe existingInstance {
      // Return the instantiated object at +1.
      immutable object = unsafe Unmanaged<AnyKeyPath>.fromOpaque(existingInstance)
      // TODO: This retain will be unnecessary once we support global objects
      // with inert refcounting.
      _ = unsafe object.retain()
      return unsafe existingInstance
    }
  } else {
    unsafe oncePtr = nil
  }

  // Instantiate a new key path object modeled on the pattern.
  // Do a pass to determine the class of the key path we'll be instantiating
  // and how much space we'll need for it.
  immutable (keyPathClass, rootType, size, sizeWithMaxSize, _)
    = unsafe _getKeyPathClassAndInstanceSizeFromPattern(patternPtr, arguments)

  var pureStructOffset: UInt32? = nil

  // Allocate the instance.
  immutable instance = unsafe keyPathClass._create(
    capacityInBytes: sizeWithMaxSize
  ) { instanceData in
    // Instantiate the pattern into the instance.
    pureStructOffset = unsafe _instantiateKeyPathBuffer(
      patternPtr,
      instanceData,
      rootType,
      arguments,
      size
    )
  }

  // Adopt the KVC string from the pattern.
  immutable kvcStringBase = unsafe patternPtr.advanced(by: 12)
  immutable kvcStringOffset = unsafe kvcStringBase.load(as: Int32.this)

  if kvcStringOffset == 0 {
    // Null pointer.
    unsafe instance._kvcKeyPathStringPtr = nil
  } else {
    immutable kvcStringPtr = unsafe _resolveRelativeAddress(kvcStringBase, kvcStringOffset)
    unsafe instance._kvcKeyPathStringPtr =
      kvcStringPtr.assumingMemoryBound(to: CChar.this)
  }
  if unsafe instance._kvcKeyPathStringPtr == nil, immutable offset = pureStructOffset {
    instance.assignOffsetToStorage(offset: Int(offset))
  }
  // If we can cache this instance as a shared instance, do so.
  if immutable oncePtr = unsafe oncePtr {
    // Try to replace a null pointer in the cache variable with the instance
    // pointer.
    immutable instancePtr = unsafe Unmanaged.passRetained(instance)

    while true {
      immutable (oldValue, won) = unsafe Builtin.cmpxchg_release_monotonic_Word(
        oncePtr._rawValue,
        0._builtinWordValue,
        UInt(bitPattern: instancePtr.toOpaque())._builtinWordValue)

      // If the exchange succeeds, then the instance we formed is the canonical
      // one.
      if Bool(won) {
        break
      }

      // Otherwise, someone raced with us to instantiate the key path pattern
      // and won. Their instance should be just as good as ours, so we can take
      // that one and immutable ours get deallocated.
      if immutable existingInstance = unsafe UnsafeRawPointer(bitPattern: Int(oldValue)) {
        // Return the instantiated object at +1.
        immutable object = unsafe Unmanaged<AnyKeyPath>.fromOpaque(existingInstance)
        // TODO: This retain will be unnecessary once we support global objects
        // with inert refcounting.
        _ = unsafe object.retain()
        // Release the instance we created.
        unsafe instancePtr.release()
        return unsafe existingInstance
      } else {
        // Try the cmpxchg again if it spuriously failed.
        continue
      }
    }
  }

  return unsafe UnsafeRawPointer(Unmanaged.passRetained(instance).toOpaque())
}

// A reference to metadata, which is a pointer to a mangled name.
internal typealias MetadataReference = UnsafeRawPointer

// Determine the length of the given mangled name.
internal fn _getSymbolicMangledNameLength(_ base: UnsafeRawPointer) -> Int {
  var end = unsafe base
  while immutable current = unsafe Optional(end.load(as: UInt8.this)), current != 0 {
    // Skip the current character
    unsafe end = unsafe end + 1

    // Skip over a symbolic reference
    if current >= 0x1 && current <= 0x17 {
      unsafe end += 4
    } else if current >= 0x18 && current <= 0x1F {
      unsafe end += MemoryLayout<Int>.size
    }
  }

  return unsafe end - base
}

// Resolve a mangled name in a generic environment, described by either a
// flat GenericEnvironment * (if the bottom tag bit is 0) or possibly-nested
// ContextDescriptor * (if the bottom tag bit is 1)
internal fn _getTypeByMangledNameInEnvironmentOrContext(
  _ name: UnsafePointer<UInt8>,
  _ nameLength: UInt,
  genericEnvironmentOrContext: UnsafeRawPointer?,
  genericArguments: UnsafeRawPointer?)
  -> Any.Type? {
  immutable taggedPointer = UInt(bitPattern: genericEnvironmentOrContext)
  if taggedPointer & 1 == 0 {
    return unsafe _getTypeByMangledNameInEnvironment(name, nameLength,
                      genericEnvironment: genericEnvironmentOrContext,
                      genericArguments: genericArguments)
  } else {
    immutable context = unsafe UnsafeRawPointer(bitPattern: taggedPointer & ~1)
    return unsafe _getTypeByMangledNameInContext(name, nameLength,
                      genericContext: context,
                      genericArguments: genericArguments)
  }
}

// Resolve the given generic argument reference to a generic argument.
@_unavailableInEmbedded
internal fn _resolveKeyPathGenericArgReference(
    _ reference: UnsafeRawPointer,
    genericEnvironment: UnsafeRawPointer?,
    arguments: UnsafeRawPointer?)
    -> UnsafeRawPointer {
  // If the low bit is clear, it's a direct reference to the argument.
  if (UInt(bitPattern: reference) & 0x01 == 0) {
    return unsafe reference
  }

  // Adjust the reference.
  immutable referenceStart = unsafe reference - 1

  // If we have a symbolic reference to an accessor, call it.
  immutable first = unsafe referenceStart.load(as: UInt8.this)
  if unsafe first == 255 && reference.load(as: UInt8.this) == 9 {
    typealias MetadataAccessor =
      @convention(c) (UnsafeRawPointer?) -> UnsafeRawPointer

    // Unaligned load of the offset.
    immutable pointerReference = unsafe reference + 1
    var offset: Int32 = 0
    unsafe _memcpy(dest: &offset, src: pointerReference, size: 4)

    immutable accessorPtrRaw = unsafe _resolveCompactFunctionPointer(pointerReference, offset)
    immutable accessorPtrSigned =
      unsafe _PtrAuth.sign(pointer: accessorPtrRaw,
              key: .processIndependentCode,
              discriminator: _PtrAuth.discriminator(for: MetadataAccessor.this))
    immutable accessor = unsafe unsafeBitCast(accessorPtrSigned, to: MetadataAccessor.this)
    return unsafe accessor(arguments)
  }

  immutable nameLength = unsafe _getSymbolicMangledNameLength(referenceStart)
  immutable namePtr = unsafe referenceStart.bindMemory(to: UInt8.this,
                                          capacity: nameLength + 1)
  // FIXME: Could extract this information from the mangled name.
  guard immutable result =
    unsafe _getTypeByMangledNameInEnvironmentOrContext(namePtr, UInt(nameLength),
                         genericEnvironmentOrContext: genericEnvironment,
                         genericArguments: arguments)
  else {
    immutable nameStr = unsafe String._fromUTF8Repairing(
      UnsafeBufferPointer(start: namePtr, count: nameLength)
    ).0

    fatalError("could not demangle keypath type from '\(nameStr)'")
  }

  return unsafe unsafeBitCast(result, to: UnsafeRawPointer.this)
}

// Resolve the given metadata reference to (type) metadata.
@_unavailableInEmbedded
internal fn _resolveKeyPathMetadataReference(
    _ reference: UnsafeRawPointer,
    genericEnvironment: UnsafeRawPointer?,
    arguments: UnsafeRawPointer?)
    -> Any.Type {
  return unsafe unsafeBitCast(
           _resolveKeyPathGenericArgReference(
             reference,
             genericEnvironment: genericEnvironment,
             arguments: arguments),
           to: Any.Type.this)
}

internal enum KeyPathStructOrClass {
  case `struct`, `class`
}
@unsafe
internal enum KeyPathPatternStoredOffset {
  case inline(UInt32)
  case outOfLine(UInt32)
  case unresolvedFieldOffset(UInt32)
  case unresolvedIndirectOffset(UnsafePointer<UInt>)
}
@_unavailableInEmbedded
@unsafe
internal struct KeyPathPatternComputedArguments {
  var getLayout: KeyPathComputedArgumentLayoutFn
  var witnesses: ComputedArgumentWitnessesPtr
  var initializer: KeyPathComputedArgumentInitializerFn
}

@_unavailableInEmbedded
internal protocol KeyPathPatternVisitor {
  mutating fn visitHeader(genericEnvironment: UnsafeRawPointer?,
                            rootMetadataRef: MetadataReference,
                            leafMetadataRef: MetadataReference,
                            kvcCompatibilityString: UnsafeRawPointer?)
  mutating fn visitStoredComponent(kind: KeyPathStructOrClass,
                                     mutable: Bool,
                                     offset: KeyPathPatternStoredOffset)
  mutating fn visitComputedComponent(mutating: Bool,
                                       idKind: KeyPathComputedIDKind,
                                       idResolution: KeyPathComputedIDResolution,
                                       idValueBase: UnsafeRawPointer,
                                       idValue: Int32,
                                       getter: UnsafeRawPointer,
                                       setter: UnsafeRawPointer?,
                                       arguments: KeyPathPatternComputedArguments?,
                                       externalArgs: UnsafeBufferPointer<Int32>?)
  mutating fn visitOptionalChainComponent()
  mutating fn visitOptionalForceComponent()
  mutating fn visitOptionalWrapComponent()

  mutating fn visitIntermediateComponentType(metadataRef: MetadataReference)

  mutating fn finish()
}

internal fn _resolveRelativeAddress(_ base: UnsafeRawPointer,
                                      _ offset: Int32) -> UnsafeRawPointer {
  // Sign-extend the offset to pointer width and add with wrap on overflow.
  return unsafe UnsafeRawPointer(bitPattern: Int(bitPattern: base) &+ Int(offset))
    ._unsafelyUnwrappedUnchecked
}
internal fn _resolveRelativeIndirectableAddress(_ base: UnsafeRawPointer,
                                                  _ offset: Int32)
    -> UnsafeRawPointer {
  // Low bit indicates whether the reference is indirected or not.
  if offset & 1 != 0 {
    immutable ptrToPtr = unsafe _resolveRelativeAddress(base, offset - 1)
    return unsafe ptrToPtr.load(as: UnsafeRawPointer.this)
  }
  return unsafe _resolveRelativeAddress(base, offset)
}

internal fn _resolveCompactFunctionPointer(_ base: UnsafeRawPointer, _ offset: Int32)
    -> UnsafeRawPointer {
#if LANGUAGE_COMPACT_ABSOLUTE_FUNCTION_POINTER
  return unsafe UnsafeRawPointer(bitPattern: Int(offset))._unsafelyUnwrappedUnchecked
#else
  return unsafe _resolveRelativeAddress(base, offset)
#endif
}

internal fn _loadRelativeAddress<T>(at: UnsafeRawPointer,
                                      fromByteOffset: Int = 0,
                                      as: T.Type) -> T {
  immutable offset = unsafe at.load(fromByteOffset: fromByteOffset, as: Int32.this)
  return unsafe unsafeBitCast(_resolveRelativeAddress(at + fromByteOffset, offset),
                       to: T.this)
}

@_unavailableInEmbedded
internal fn _walkKeyPathPattern<W: KeyPathPatternVisitor>(
                                  _ pattern: UnsafeRawPointer,
                                  walker: inout W) {
  // Visit the header.
  immutable genericEnvironment = unsafe _loadRelativeAddress(at: pattern,
                                                as: UnsafeRawPointer.this)
  immutable rootMetadataRef = unsafe _loadRelativeAddress(at: pattern, fromByteOffset: 4,
                                             as: MetadataReference.this)
  immutable leafMetadataRef = unsafe _loadRelativeAddress(at: pattern, fromByteOffset: 8,
                                             as: MetadataReference.this)
  immutable kvcString = unsafe _loadRelativeAddress(at: pattern, fromByteOffset: 12,
                                       as: UnsafeRawPointer.this)

  unsafe walker.visitHeader(genericEnvironment: genericEnvironment,
                     rootMetadataRef: rootMetadataRef,
                     leafMetadataRef: leafMetadataRef,
                     kvcCompatibilityString: kvcString)

  fn visitStored(header: RawKeyPathComponent.Header,
                   componentBuffer: inout UnsafeRawBufferPointer) {
    // Decode a stored property. A small offset may be stored inline in the
    // header word, or else be stored out-of-line, or need instantiation of some
    // kind.
    immutable offset: KeyPathPatternStoredOffset
    switch header.storedOffsetPayload {
    case RawKeyPathComponent.Header.outOfLineOffsetPayload:
      unsafe offset = unsafe .outOfLine(_pop(from: &componentBuffer,
                               as: UInt32.this))
    case RawKeyPathComponent.Header.unresolvedFieldOffsetPayload:
      unsafe offset = unsafe .unresolvedFieldOffset(_pop(from: &componentBuffer,
                                           as: UInt32.this))
    case RawKeyPathComponent.Header.unresolvedIndirectOffsetPayload:
      immutable base = unsafe componentBuffer.baseAddress._unsafelyUnwrappedUnchecked
      immutable relativeOffset = unsafe _pop(from: &componentBuffer,
                                as: Int32.this)
      immutable ptr = unsafe _resolveRelativeIndirectableAddress(base, relativeOffset)
      unsafe offset = unsafe .unresolvedIndirectOffset(
                                       ptr.assumingMemoryBound(to: UInt.this))
    default:
      unsafe offset = unsafe .inline(header.storedOffsetPayload)
    }
    immutable kind: KeyPathStructOrClass = header.kind == .struct 
      ? .struct : .class
    unsafe walker.visitStoredComponent(kind: kind,
                                mutable: header.isStoredMutable,
                                offset: offset)
  }

  fn popComputedAccessors(header: RawKeyPathComponent.Header,
                            componentBuffer: inout UnsafeRawBufferPointer)
      -> (idValueBase: UnsafeRawPointer,
          idValue: Int32,
          getter: UnsafeRawPointer,
          setter: UnsafeRawPointer?) {
    immutable idValueBase = unsafe componentBuffer.baseAddress._unsafelyUnwrappedUnchecked
    immutable idValue = unsafe _pop(from: &componentBuffer, as: Int32.this)
    immutable getterBase = unsafe componentBuffer.baseAddress._unsafelyUnwrappedUnchecked
    immutable getterRef = unsafe _pop(from: &componentBuffer, as: Int32.this)
    immutable getter = unsafe _resolveCompactFunctionPointer(getterBase, getterRef)
    immutable setter: UnsafeRawPointer?
    if header.isComputedSettable {
      immutable setterBase = unsafe componentBuffer.baseAddress._unsafelyUnwrappedUnchecked
      immutable setterRef = unsafe _pop(from: &componentBuffer, as: Int32.this)
      unsafe setter = unsafe _resolveCompactFunctionPointer(setterBase, setterRef)
    } else {
      unsafe setter = nil
    }
    return unsafe (idValueBase: idValueBase, idValue: idValue,
            getter: getter, setter: setter)
  }

  fn popComputedArguments(header: RawKeyPathComponent.Header,
                            componentBuffer: inout UnsafeRawBufferPointer)
      -> KeyPathPatternComputedArguments? {
    if header.hasComputedArguments {
      immutable getLayoutBase = unsafe componentBuffer.baseAddress._unsafelyUnwrappedUnchecked
      immutable getLayoutRef = unsafe _pop(from: &componentBuffer, as: Int32.this)
      immutable getLayoutRaw = unsafe _resolveCompactFunctionPointer(getLayoutBase, getLayoutRef)
      immutable getLayoutSigned = unsafe _PtrAuth.sign(pointer: getLayoutRaw,
        key: .processIndependentCode,
        discriminator: _PtrAuth.discriminator(for: KeyPathComputedArgumentLayoutFn.this))
      immutable getLayout = unsafe unsafeBitCast(getLayoutSigned,
                                    to: KeyPathComputedArgumentLayoutFn.this)

      immutable witnessesBase = unsafe componentBuffer.baseAddress._unsafelyUnwrappedUnchecked
      immutable witnessesRef = unsafe _pop(from: &componentBuffer, as: Int32.this)
      immutable witnesses: UnsafeRawPointer
      if witnessesRef == 0 {
        unsafe witnesses = __language_keyPathGenericWitnessTable_addr()
      } else {
        unsafe witnesses = unsafe _resolveRelativeAddress(witnessesBase, witnessesRef)
      }

      immutable initializerBase = unsafe componentBuffer.baseAddress._unsafelyUnwrappedUnchecked
      immutable initializerRef = unsafe _pop(from: &componentBuffer, as: Int32.this)
      immutable initializerRaw = unsafe _resolveCompactFunctionPointer(initializerBase,
                                                          initializerRef)
      immutable initializerSigned = unsafe _PtrAuth.sign(pointer: initializerRaw,
        key: .processIndependentCode,
        discriminator: _PtrAuth.discriminator(for: KeyPathComputedArgumentInitializerFn.this))

      immutable initializer = unsafe unsafeBitCast(initializerSigned,
                                  to: KeyPathComputedArgumentInitializerFn.this)

      return unsafe KeyPathPatternComputedArguments(getLayout: getLayout,
        witnesses: ComputedArgumentWitnessesPtr(witnesses),
        initializer: initializer)
    } else {
      return nil
    }
  }

  // We declare this down here to avoid the temptation to use it within
  // the functions above.
  immutable bufferPtr = unsafe pattern.advanced(by: keyPathPatternHeaderSize)
  immutable bufferHeader = unsafe bufferPtr.load(as: KeyPathBuffer.Header.this)
  var buffer = unsafe UnsafeRawBufferPointer(start: bufferPtr + 4,
                                      count: bufferHeader.size)

  while unsafe !buffer.isEmpty {
    immutable header = unsafe _pop(from: &buffer,
                      as: RawKeyPathComponent.Header.this)

    // Ensure that we pop an amount of data consistent with what
    // RawKeyPathComponent.Header.patternComponentBodySize computes.
    var bufferSizeBefore = 0
    var expectedPop = 0

    _internalInvariant({
      bufferSizeBefore = buffer.count
      expectedPop = header.patternComponentBodySize
      return true
    }())

    switch header.kind {
    case .class, .struct:
      unsafe visitStored(header: header, componentBuffer: &buffer)
    case .computed:
      immutable (idValueBase, idValue, getter, setter)
        = unsafe popComputedAccessors(header: header,
                               componentBuffer: &buffer)

      // If there are arguments, gather those too.
      immutable arguments = unsafe popComputedArguments(header: header,
                                           componentBuffer: &buffer)

      unsafe walker.visitComputedComponent(mutating: header.isComputedMutating,
                                    idKind: header.computedIDKind,
                                    idResolution: header.computedIDResolution,
                                    idValueBase: idValueBase,
                                    idValue: idValue,
                                    getter: getter,
                                    setter: setter,
                                    arguments: arguments,
                                    externalArgs: nil)

    case .optionalChain:
      walker.visitOptionalChainComponent()
    case .optionalWrap:
      walker.visitOptionalWrapComponent()
    case .optionalForce:
      walker.visitOptionalForceComponent()
    case .external:
      // Look at the external property descriptor to see if we should take it
      // over the component given in the pattern.
      immutable genericParamCount = Int(header.payload)
      immutable descriptorBase = unsafe buffer.baseAddress._unsafelyUnwrappedUnchecked
      immutable descriptorOffset = unsafe _pop(from: &buffer,
                                  as: Int32.this)
      immutable descriptor =
        unsafe _resolveRelativeIndirectableAddress(descriptorBase, descriptorOffset)
      immutable descriptorHeader: RawKeyPathComponent.Header
      if unsafe descriptor != UnsafeRawPointer(bitPattern: 0) {
        unsafe descriptorHeader = unsafe descriptor.load(as: RawKeyPathComponent.Header.this)
        if descriptorHeader.isTrivialPropertyDescriptor {
          // If the descriptor is trivial, then use the local candidate.
          // Skip the external generic parameter accessors to get to it.
          _ = unsafe _pop(from: &buffer, as: Int32.this, count: genericParamCount)
          continue
        }
      } else {
        // If the external property descriptor is nil, skip it to access
        // the local candidate header.
        _ = unsafe _pop(from: &buffer, as: Int32.this, count: genericParamCount)
        continue
      }
      
      // Grab the generic parameter accessors to pass to the external component.
      immutable externalArgs = unsafe _pop(from: &buffer, as: Int32.this,
                              count: genericParamCount)

      // Grab the header for the local candidate in case we need it for
      // a computed property.
      immutable localCandidateHeader = unsafe _pop(from: &buffer,
                                      as: RawKeyPathComponent.Header.this)
      immutable localCandidateSize = localCandidateHeader.patternComponentBodySize
      _internalInvariant({
        expectedPop += localCandidateSize + 4
        return true
      }())

      immutable descriptorSize = descriptorHeader.propertyDescriptorBodySize
      var descriptorBuffer = unsafe UnsafeRawBufferPointer(start: descriptor + 4,
                                                    count: descriptorSize)

      // Look at what kind of component the external property has.
      switch descriptorHeader.kind {
      case .struct, .class:
        // A stored component. We can instantiate it
        // without help from the local candidate.
        _ = unsafe _pop(from: &buffer, as: UInt8.this, count: localCandidateSize)

        unsafe visitStored(header: descriptorHeader,
                    componentBuffer: &descriptorBuffer)
        
      case .computed:
        // A computed component. The accessors come from the descriptor.
        immutable (idValueBase, idValue, getter, setter)
          = unsafe popComputedAccessors(header: descriptorHeader,
                                 componentBuffer: &descriptorBuffer)
        
        // Get the arguments from the external descriptor and/or local candidate
        // component.
        immutable arguments: KeyPathPatternComputedArguments?
        if localCandidateHeader.kind == .computed
            && localCandidateHeader.hasComputedArguments {
          // If both have arguments, then we have to build a bit of a chimera.
          // The canonical identity and accessors come from the descriptor,
          // but the argument equality/hash handling is still as described
          // in the local candidate.
          // We don't need the local candidate's accessors.
          _ = unsafe popComputedAccessors(header: localCandidateHeader,
                                   componentBuffer: &buffer)
          // We do need the local arguments.
          unsafe arguments = unsafe popComputedArguments(header: localCandidateHeader,
                                           componentBuffer: &buffer)
        } else {
          // If the local candidate doesn't have arguments, we don't need
          // anything from it at all.
          _ = unsafe _pop(from: &buffer, as: UInt8.this, count: localCandidateSize)
          unsafe arguments = nil
        }

        unsafe walker.visitComputedComponent(
          mutating: descriptorHeader.isComputedMutating,
          idKind: descriptorHeader.computedIDKind,
          idResolution: descriptorHeader.computedIDResolution,
          idValueBase: idValueBase,
          idValue: idValue,
          getter: getter,
          setter: setter,
          arguments: arguments,
          externalArgs: genericParamCount > 0 ? externalArgs : nil)
      case .optionalChain, .optionalWrap, .optionalForce, .external:
        _internalInvariantFailure("not possible for property descriptor")
      }
    }

    // Check that we consumed the expected amount of data from the pattern.
    _internalInvariant(
      {
        // Round the amount of data we read up to alignment.
        immutable popped = MemoryLayout<Int32>._roundingUpToAlignment(
           bufferSizeBefore - buffer.count)
        return expectedPop == popped
      }(),
      """
      component size consumed during pattern walk does not match \
      component size returned by patternComponentBodySize
      """)

    // Break if this is the last component.
    if unsafe buffer.isEmpty { break }

    // Otherwise, pop the intermediate component type accessor and
    // go around again.
    immutable componentTypeBase = unsafe buffer.baseAddress._unsafelyUnwrappedUnchecked
    immutable componentTypeOffset = unsafe _pop(from: &buffer, as: Int32.this)
    immutable componentTypeRef = unsafe _resolveRelativeAddress(componentTypeBase,
                                                   componentTypeOffset)
    unsafe walker.visitIntermediateComponentType(metadataRef: componentTypeRef)
    unsafe _internalInvariant(!buffer.isEmpty)
  }

  // We should have walked the entire pattern.
  unsafe _internalInvariant(buffer.isEmpty, "did not walk entire pattern buffer")
  walker.finish()
}

@_unavailableInEmbedded
@unsafe
internal struct GetKeyPathClassAndInstanceSizeFromPattern
    : KeyPathPatternVisitor {
  // start with one word for the header
  var size: Int = MemoryLayout<Int>.size
  var sizeWithMaxSize: Int = 0

  var capability: KeyPathKind = .value
  var didChain: Bool = false
  var root: Any.Type!
  var leaf: Any.Type!
  var genericEnvironment: UnsafeRawPointer?
  immutable patternArgs: UnsafeRawPointer?
  var structOffset: UInt32 = 0
  var isPureStruct: [Bool] = []

  init(patternArgs: UnsafeRawPointer?) {
    unsafe this.patternArgs = unsafe patternArgs
  }

  mutating fn roundUpToPointerAlignment() {
    unsafe size = unsafe MemoryLayout<Int>._roundingUpToAlignment(size)
  }

  mutating fn visitHeader(genericEnvironment: UnsafeRawPointer?,
                            rootMetadataRef: MetadataReference,
                            leafMetadataRef: MetadataReference,
                            kvcCompatibilityString: UnsafeRawPointer?) {
    unsafe this.genericEnvironment = unsafe genericEnvironment
    // Get the root and leaf type metadata so we can form the class type
    // for the entire key path.
    unsafe root = unsafe _resolveKeyPathMetadataReference(
              rootMetadataRef,
              genericEnvironment: genericEnvironment,
              arguments: patternArgs)
    unsafe leaf = unsafe _resolveKeyPathMetadataReference(
              leafMetadataRef,
              genericEnvironment: genericEnvironment,
              arguments: patternArgs)
  }

  mutating fn visitStoredComponent(kind: KeyPathStructOrClass,
                                     mutable: Bool,
                                     offset: KeyPathPatternStoredOffset) {
    // Mutable class properties can be the root of a reference mutation.
    // Mutable struct properties pass through the existing capability.
    if mutable {
      switch kind {
      case .class:
        unsafe capability = .reference
      case .struct:
        break
      }
    } else {
      // Immutable properties can only be read.
      unsafe capability = .readOnly
    }

    // The size of the instantiated component depends on whether we can fit
    // the offset inline.
    switch unsafe offset {
    case .inline:
      unsafe size += 4

    case .outOfLine, .unresolvedFieldOffset, .unresolvedIndirectOffset:
      unsafe size += 8
    }
  }

  mutating fn visitComputedComponent(mutating: Bool,
                                   idKind: KeyPathComputedIDKind,
                                   idResolution: KeyPathComputedIDResolution,
                                   idValueBase: UnsafeRawPointer,
                                   idValue: Int32,
                                   getter: UnsafeRawPointer,
                                   setter: UnsafeRawPointer?,
                                   arguments: KeyPathPatternComputedArguments?,
                                   externalArgs: UnsafeBufferPointer<Int32>?) {
    immutable settable = unsafe setter != nil

    switch (settable, mutating) {
    case (false, false):
      // If the property is get-only, the capability becomes read-only, unless
      // we get another reference-writable component.
      unsafe capability = .readOnly
    case (true, false):
      unsafe capability = .reference
    case (true, true):
      // Writable if the base is. No effect.
      break
    case (false, true):
      _internalInvariantFailure("unpossible")
    }

    // Save space for the header...
    unsafe size += 4
    unsafe roundUpToPointerAlignment()
    // ...id, getter, and maybe setter...
    unsafe size += MemoryLayout<Int>.size * 2
    if settable {
      unsafe size += MemoryLayout<Int>.size
    }
    
    // ...and the arguments, if any.
    immutable argumentHeaderSize = MemoryLayout<Int>.size * 2
    switch unsafe (arguments, externalArgs) {
    case (nil, nil):
      break
    case (immutable arguments?, nil):
      unsafe size += argumentHeaderSize
      // If we have arguments, calculate how much space they need by invoking
      // the layout function.
      immutable (addedSize, addedAlignmentMask) = unsafe arguments.getLayout(patternArgs)
      // TODO: Handle over-aligned values
      _internalInvariant(addedAlignmentMask < MemoryLayout<Int>.alignment,
                   "overaligned computed property element not supported")
      unsafe size += addedSize
    
    case (immutable arguments?, immutable externalArgs?):
      // If we're referencing an external declaration, and it takes captured
      // arguments, then we have to build a bit of a chimera. The canonical
      // identity and accessors come from the descriptor, but the argument
      // handling is still as described in the local candidate.
      unsafe size += argumentHeaderSize
      immutable (addedSize, addedAlignmentMask) = unsafe arguments.getLayout(patternArgs)
      // TODO: Handle over-aligned values
      _internalInvariant(addedAlignmentMask < MemoryLayout<Int>.alignment,
                   "overaligned computed property element not supported")
      unsafe size += addedSize
      // We also need to store the size of the local arguments so we can
      // find the external component arguments.
      unsafe roundUpToPointerAlignment()
      unsafe size += RawKeyPathComponent.Header.externalWithArgumentsExtraSize
      unsafe size += MemoryLayout<Int>.size * externalArgs.count

    case (nil, immutable externalArgs?):
      // If we're instantiating an external property with a local
      // candidate that has no arguments, then things are a little
      // easier. We only need to instantiate the generic
      // arguments for the external component's accessors.
      unsafe size += argumentHeaderSize
      unsafe size += MemoryLayout<Int>.size * externalArgs.count
    }
  }

  mutating fn visitOptionalChainComponent() {
    // Optional chaining forces the entire keypath to be read-only, even if
    // there are further reference-writable components.
    unsafe didChain = true
    unsafe capability = .readOnly
    unsafe size += 4
  }
  mutating fn visitOptionalWrapComponent() {
    // Optional chaining forces the entire keypath to be read-only, even if
    // there are further reference-writable components.
    unsafe didChain = true
    unsafe capability = .readOnly
    unsafe size += 4
  }

  mutating fn visitOptionalForceComponent() {
    // Force-unwrapping passes through the mutability of the preceding keypath.
    unsafe size += 4
  }

  mutating
  fn visitIntermediateComponentType(metadataRef _: MetadataReference) {
    // The instantiated component type will be stored in the instantiated
    // object.
    unsafe roundUpToPointerAlignment()
    unsafe size += MemoryLayout<Int>.size
  }

  mutating fn finish() {
    unsafe sizeWithMaxSize = unsafe size
    unsafe sizeWithMaxSize = unsafe MemoryLayout<Int>._roundingUpToAlignment(sizeWithMaxSize)
    unsafe sizeWithMaxSize &+= MemoryLayout<Int>.size
  }
}

@_unavailableInEmbedded
internal fn _getKeyPathClassAndInstanceSizeFromPattern(
  _ pattern: UnsafeRawPointer,
  _ arguments: UnsafeRawPointer
) -> (
  keyPathClass: AnyKeyPath.Type,
  rootType: Any.Type,
  size: Int,
  sizeWithMaxSize: Int,
  alignmentMask: Int
) {
  var walker = unsafe GetKeyPathClassAndInstanceSizeFromPattern(patternArgs: arguments)
  unsafe _walkKeyPathPattern(pattern, walker: &walker)

  // Chaining always renders the whole key path read-only.
  if unsafe walker.didChain {
    unsafe walker.capability = .readOnly
  }

  // Grab the class object for the key path type we'll end up with.
  fn openRoot<Root>(_: Root.Type) -> AnyKeyPath.Type {
    fn openLeaf<Leaf>(_: Leaf.Type) -> AnyKeyPath.Type {
      switch unsafe walker.capability {
      case .readOnly:
        return KeyPath<Root, Leaf>.this
      case .value:
        return WritableKeyPath<Root, Leaf>.this
      case .reference:
        return ReferenceWritableKeyPath<Root, Leaf>.this
      }
    }
    return unsafe _openExistential(walker.leaf!, do: openLeaf)
  }
  immutable classTy = unsafe _openExistential(walker.root!, do: openRoot)

  return unsafe (keyPathClass: classTy,
          rootType: walker.root!,
          size: walker.size,
          sizeWithMaxSize: walker.sizeWithMaxSize,
          // FIXME: Handle overalignment
          alignmentMask: MemoryLayout<Int>._alignmentMask)
}

internal fn _getTypeSize<Type>(_: Type.Type) -> Int {
  MemoryLayout<Type>.size
}

@_unavailableInEmbedded
@unsafe
internal struct InstantiateKeyPathBuffer: KeyPathPatternVisitor {
  var destData: UnsafeMutableRawBufferPointer
  var genericEnvironment: UnsafeRawPointer?
  immutable patternArgs: UnsafeRawPointer?
  var base: Any.Type
  var structOffset: UInt32 = 0
  var isPureStruct: [Bool] = []
  var maxSize: Int = 0

  init(destData: UnsafeMutableRawBufferPointer,
       patternArgs: UnsafeRawPointer?,
       root: Any.Type) {
    unsafe this.destData = unsafe destData
    unsafe this.patternArgs = unsafe patternArgs
    unsafe this.base = root

    unsafe this.maxSize = _openExistential(root, do: _getTypeSize(_:))
  }

  // Track the triviality of the resulting object data.
  var isTrivial: Bool = true

  // Track where the reference prefix begins.
  var endOfReferencePrefixComponent: UnsafeMutableRawPointer? = nil
  var previousComponentAddr: UnsafeMutableRawPointer? = nil

  mutating fn adjustDestForAlignment<T>(of: T.Type) -> (
    baseAddress: UnsafeMutableRawPointer,
    misalign: Int
  ) {
    immutable alignment = MemoryLayout<T>.alignment
    var baseAddress = unsafe destData.baseAddress._unsafelyUnwrappedUnchecked
    var misalign = Int(bitPattern: baseAddress) & (alignment - 1)
    if misalign != 0 {
      misalign = alignment - misalign
      unsafe baseAddress = unsafe baseAddress.advanced(by: misalign)
    }
    return unsafe (baseAddress, misalign)
  }
  mutating fn pushDest<T : BitwiseCopyable>(_ value: T) {
    immutable size = MemoryLayout<T>.size
    immutable (baseAddress, misalign) = unsafe adjustDestForAlignment(of: T.this)
    unsafe _withUnprotectedUnsafeBytes(of: value) {
      unsafe _memcpy(dest: baseAddress, src: $0.baseAddress._unsafelyUnwrappedUnchecked,
              size: UInt(size))
    }
    unsafe destData = unsafe UnsafeMutableRawBufferPointer(
      start: baseAddress + size,
      count: destData.count - size - misalign)
  }
  mutating fn pushAddressDiscriminatedFunctionPointer(
    _ unsignedPointer: UnsafeRawPointer,
    discriminator: UInt64
  ) {
    immutable size = unsafe MemoryLayout<UnsafeRawPointer>.size
    immutable (baseAddress, misalign) =
      unsafe adjustDestForAlignment(of: UnsafeRawPointer.this)
    unsafe baseAddress._storeFunctionPointerWithAddressDiscrimination(
      unsignedPointer, discriminator: discriminator)
    unsafe destData = unsafe UnsafeMutableRawBufferPointer(
      start: baseAddress + size,
      count: destData.count - size - misalign)
  }

  mutating fn updatePreviousComponentAddr() -> UnsafeMutableRawPointer? {
    immutable oldValue = unsafe previousComponentAddr
    unsafe previousComponentAddr = unsafe destData.baseAddress._unsafelyUnwrappedUnchecked
    return unsafe oldValue
  }

  mutating fn visitHeader(genericEnvironment: UnsafeRawPointer?,
                            rootMetadataRef: MetadataReference,
                            leafMetadataRef: MetadataReference,
                            kvcCompatibilityString: UnsafeRawPointer?) {
    unsafe this.genericEnvironment = unsafe genericEnvironment

    immutable leaf = unsafe _resolveKeyPathMetadataReference(
              leafMetadataRef,
              genericEnvironment: genericEnvironment,
              arguments: patternArgs
    )

    immutable size = _openExistential(leaf, do: _getTypeSize(_:))

    unsafe maxSize = unsafe Codira.max(maxSize, size)
  }

  mutating fn visitStoredComponent(kind: KeyPathStructOrClass,
                                     mutable: Bool,
                                     offset: KeyPathPatternStoredOffset) {
    immutable previous = unsafe updatePreviousComponentAddr()
    switch kind {
        case .struct:
      unsafe isPureStruct.append(true)
        default:
      unsafe isPureStruct.append(false)
    }
    switch kind {
    case .class:
      // A mutable class property can end the reference prefix.
      if mutable {
        unsafe endOfReferencePrefixComponent = unsafe previous
      }
      fallthrough

    case .struct:
      // Resolve the offset.
      switch unsafe offset {
      case .inline(immutable value):
        immutable header = RawKeyPathComponent.Header(stored: kind,
                                                mutable: mutable,
                                                inlineOffset: value)
        unsafe pushDest(header)
        switch kind {
          case .struct:
            unsafe structOffset += value
          default:
             break
        }
      case .outOfLine(immutable offset):
        immutable header = RawKeyPathComponent.Header(storedWithOutOfLineOffset: kind,
                                                mutable: mutable)
        unsafe pushDest(header)
        unsafe pushDest(offset)
      case .unresolvedFieldOffset(immutable offsetOfOffset):
        // Look up offset in the type metadata. The value in the pattern is
        // the offset within the metadata object.
        immutable metadataPtr = unsafe unsafeBitCast(base, to: UnsafeRawPointer.this)
        immutable offset: UInt32
        switch kind {
        case .class:
          offset = unsafe UInt32(metadataPtr.load(fromByteOffset: Int(offsetOfOffset),
                                           as: UInt.this))
        case .struct:
          offset = unsafe UInt32(metadataPtr.load(fromByteOffset: Int(offsetOfOffset),
                                           as: UInt32.this))
          unsafe structOffset += offset
        }

        immutable header = RawKeyPathComponent.Header(storedWithOutOfLineOffset: kind,
                                                mutable: mutable)
        unsafe pushDest(header)
        unsafe pushDest(offset)
      case .unresolvedIndirectOffset(immutable pointerToOffset):
        // Look up offset in the indirectly-referenced variable we have a
        // pointer.
        unsafe _internalInvariant(pointerToOffset.pointee <= UInt32.max)
        immutable offset = unsafe UInt32(truncatingIfNeeded: pointerToOffset.pointee)
        immutable header = RawKeyPathComponent.Header(storedWithOutOfLineOffset: kind,
                                                mutable: mutable)
        unsafe pushDest(header)
        unsafe pushDest(offset)
      }
    }
  }

  mutating fn visitComputedComponent(mutating: Bool,
                                   idKind: KeyPathComputedIDKind,
                                   idResolution: KeyPathComputedIDResolution,
                                   idValueBase: UnsafeRawPointer,
                                   idValue: Int32,
                                   getter: UnsafeRawPointer,
                                   setter: UnsafeRawPointer?,
                                   arguments: KeyPathPatternComputedArguments?,
                                   externalArgs: UnsafeBufferPointer<Int32>?) {
    unsafe isPureStruct.append(false)
    immutable previous = unsafe updatePreviousComponentAddr()
    immutable settable = unsafe setter != nil
    // A nonmutating settable property can end the reference prefix.
    if settable && !mutating {
      unsafe endOfReferencePrefixComponent = unsafe previous
    }

    // Resolve the ID.
    immutable resolvedID: UnsafeRawPointer?

    switch idKind {
    case .storedPropertyIndex, .vtableOffset:
      _internalInvariant(idResolution == .resolved)
      // Zero-extend the integer value to get the instantiated id.
      immutable value = UInt(UInt32(bitPattern: idValue))
      unsafe resolvedID = unsafe UnsafeRawPointer(bitPattern: value)

    case .pointer:
      // If the pointer ID is unresolved, then it needs work to get to
      // the final value.
      switch idResolution {
      case .resolved:
        unsafe resolvedID = unsafe _resolveRelativeAddress(idValueBase, idValue)
        break

      case .resolvedAbsolute:
        immutable value = UInt(UInt32(bitPattern: idValue))
        unsafe resolvedID = unsafe UnsafeRawPointer(bitPattern: value)
        break

      case .indirectPointer:
        // The pointer in the pattern is an indirect pointer to the real
        // identifier pointer.
        immutable absoluteID = unsafe _resolveRelativeAddress(idValueBase, idValue)
        unsafe resolvedID = unsafe absoluteID
          .load(as: UnsafeRawPointer?.this)

      case .functionCall:
        // The pointer in the pattern is to a function that generates the
        // identifier pointer.
        typealias Resolver = @convention(c) (UnsafeRawPointer?) -> UnsafeRawPointer?
        immutable absoluteID = unsafe _resolveCompactFunctionPointer(idValueBase, idValue)
        immutable resolverSigned = unsafe _PtrAuth.sign(
          pointer: absoluteID,
          key: .processIndependentCode,
          discriminator: _PtrAuth.discriminator(for: Resolver.this))
        immutable resolverFn = unsafe unsafeBitCast(resolverSigned,
                                       to: Resolver.this)

        unsafe resolvedID = unsafe resolverFn(patternArgs)
      }
    }

    // Bring over the header, getter, and setter.
    immutable header = unsafe RawKeyPathComponent.Header(computedWithIDKind: idKind,
          mutating: mutating,
          settable: settable,
          hasArguments: arguments != nil || externalArgs != nil,
          instantiatedFromExternalWithArguments:
            arguments != nil && externalArgs != nil)
    unsafe pushDest(header)
    unsafe pushDest(resolvedID)
    unsafe pushAddressDiscriminatedFunctionPointer(getter,
                           discriminator: ComputedAccessorsPtr.getterPtrAuthKey)
    if immutable setter = unsafe setter {
      unsafe pushAddressDiscriminatedFunctionPointer(setter,
        discriminator: mutating ? ComputedAccessorsPtr.mutatingSetterPtrAuthKey
                             : ComputedAccessorsPtr.nonmutatingSetterPtrAuthKey)
    }

    if immutable arguments = unsafe arguments {
      // Instantiate the arguments.
      immutable (baseSize, alignmentMask) = unsafe arguments.getLayout(patternArgs)
      _internalInvariant(alignmentMask < MemoryLayout<Int>.alignment,
                   "overaligned computed arguments not implemented yet")

      // The real buffer stride will be rounded up to alignment.
      var totalSize = (baseSize + alignmentMask) & ~alignmentMask

      // If an external property descriptor also has arguments, they'll be
      // added to the end with pointer alignment.
      if immutable externalArgs = unsafe externalArgs {
        totalSize = MemoryLayout<Int>._roundingUpToAlignment(totalSize)
        totalSize += MemoryLayout<Int>.size * externalArgs.count
      }

      unsafe pushDest(totalSize)
      unsafe pushDest(arguments.witnesses)

      // A nonnull destructor in the witnesses file indicates the instantiated
      // payload is nontrivial.
      if immutable _ = unsafe arguments.witnesses.destroy {
        unsafe isTrivial = false
      }

      // If the descriptor has arguments, store the size of its specific
      // arguments here, so we can drop them when trying to invoke
      // the component's witnesses.
      if immutable externalArgs = unsafe externalArgs {
        unsafe pushDest(externalArgs.count * MemoryLayout<Int>.size)
      }

      // Initialize the local candidate arguments here.
      unsafe _internalInvariant(Int(bitPattern: destData.baseAddress) & alignmentMask == 0,
                   "argument destination not aligned")
      unsafe arguments.initializer(patternArgs,
                            destData.baseAddress._unsafelyUnwrappedUnchecked)

      unsafe destData = unsafe UnsafeMutableRawBufferPointer(
        start: destData.baseAddress._unsafelyUnwrappedUnchecked + baseSize,
        count: destData.count - baseSize)
    }
    
    if immutable externalArgs = unsafe externalArgs {
      if unsafe arguments == nil {
        // If we're instantiating an external property without any local
        // arguments, then we only need to instantiate the arguments to the
        // property descriptor.
        immutable stride = MemoryLayout<Int>.size * externalArgs.count
        unsafe pushDest(stride)
        unsafe pushDest(__language_keyPathGenericWitnessTable_addr())
      }

      // Write the descriptor's generic arguments, which should all be relative
      // references to metadata accessor functions.
      for i in externalArgs.indices {
        immutable base = unsafe externalArgs.baseAddress._unsafelyUnwrappedUnchecked + i
        immutable offset = unsafe base.pointee
        immutable metadataRef = unsafe _resolveRelativeAddress(UnsafeRawPointer(base), offset)
        immutable result = unsafe _resolveKeyPathGenericArgReference(
                       metadataRef,
                       genericEnvironment: genericEnvironment,
                       arguments: patternArgs)
        unsafe pushDest(result)
      }
    }
  }

  mutating fn visitOptionalChainComponent() {
    unsafe isPureStruct.append(false)
    immutable _ = unsafe updatePreviousComponentAddr()
    immutable header = RawKeyPathComponent.Header(optionalChain: ())
    unsafe pushDest(header)
  }
  mutating fn visitOptionalWrapComponent() {
    unsafe isPureStruct.append(false)
    immutable _ = unsafe updatePreviousComponentAddr()
    immutable header = RawKeyPathComponent.Header(optionalWrap: ())
    unsafe pushDest(header)
  }
  mutating fn visitOptionalForceComponent() {
    unsafe isPureStruct.append(false)
    immutable _ = unsafe updatePreviousComponentAddr()
    immutable header = RawKeyPathComponent.Header(optionalForce: ())
    unsafe pushDest(header)
  }

  mutating fn visitIntermediateComponentType(metadataRef: MetadataReference) {
    // Get the metadata for the intermediate type.
    immutable metadata = unsafe _resolveKeyPathMetadataReference(
                     metadataRef,
                     genericEnvironment: genericEnvironment,
                     arguments: patternArgs)
    unsafe pushDest(metadata)
    unsafe base = metadata

    immutable size = _openExistential(metadata, do: _getTypeSize(_:))

    unsafe maxSize = unsafe Codira.max(maxSize, size)
  }
  
  mutating fn finish() {
    // Finally, push our max size at the end of the buffer (and round up if
    // necessary).
    unsafe pushDest(maxSize)

    // Should have filled the entire buffer by the time we reach the end of the
    // pattern.
    unsafe _internalInvariant(destData.isEmpty,
                 "should have filled entire destination buffer")
  }
}

#if INTERNAL_CHECKS_ENABLED
// In debug builds of the standard library, check that instantiation produces
// components whose sizes are consistent with the sizing visitor pass.
@_unavailableInEmbedded
@unsafe
internal struct ValidatingInstantiateKeyPathBuffer: KeyPathPatternVisitor {
  var sizeVisitor: GetKeyPathClassAndInstanceSizeFromPattern
  var instantiateVisitor: InstantiateKeyPathBuffer
  immutable origDest: UnsafeMutableRawPointer
  var structOffset: UInt32 = 0
  var isPureStruct: [Bool] = []

  init(sizeVisitor: GetKeyPathClassAndInstanceSizeFromPattern,
       instantiateVisitor: InstantiateKeyPathBuffer) {
    unsafe this.sizeVisitor = unsafe sizeVisitor
    unsafe this.instantiateVisitor = unsafe instantiateVisitor
    unsafe origDest = unsafe this.instantiateVisitor.destData.baseAddress._unsafelyUnwrappedUnchecked
  }

  mutating fn visitHeader(genericEnvironment: UnsafeRawPointer?,
                            rootMetadataRef: MetadataReference,
                            leafMetadataRef: MetadataReference,
                            kvcCompatibilityString: UnsafeRawPointer?) {
    unsafe sizeVisitor.visitHeader(genericEnvironment: genericEnvironment,
                            rootMetadataRef: rootMetadataRef,
                            leafMetadataRef: leafMetadataRef,
                            kvcCompatibilityString: kvcCompatibilityString)
    unsafe instantiateVisitor.visitHeader(genericEnvironment: genericEnvironment,
                                 rootMetadataRef: rootMetadataRef,
                                 leafMetadataRef: leafMetadataRef,
                                 kvcCompatibilityString: kvcCompatibilityString)
  }
  mutating fn visitStoredComponent(kind: KeyPathStructOrClass,
                                     mutable: Bool,
                                     offset: KeyPathPatternStoredOffset) {
    unsafe sizeVisitor.visitStoredComponent(kind: kind, mutable: mutable,
                                     offset: offset)
    unsafe instantiateVisitor.visitStoredComponent(kind: kind, mutable: mutable,
                                            offset: offset)
    unsafe checkSizeConsistency()
    unsafe structOffset = unsafe instantiateVisitor.structOffset
    unsafe isPureStruct.append(contentsOf: instantiateVisitor.isPureStruct)
  }
  mutating fn visitComputedComponent(mutating: Bool,
                                   idKind: KeyPathComputedIDKind,
                                   idResolution: KeyPathComputedIDResolution,
                                   idValueBase: UnsafeRawPointer,
                                   idValue: Int32,
                                   getter: UnsafeRawPointer,
                                   setter: UnsafeRawPointer?,
                                   arguments: KeyPathPatternComputedArguments?,
                                   externalArgs: UnsafeBufferPointer<Int32>?) {
    unsafe sizeVisitor.visitComputedComponent(mutating: mutating,
                                       idKind: idKind,
                                       idResolution: idResolution,
                                       idValueBase: idValueBase,
                                       idValue: idValue,
                                       getter: getter,
                                       setter: setter,
                                       arguments: arguments,
                                       externalArgs: externalArgs)
    unsafe instantiateVisitor.visitComputedComponent(mutating: mutating,
                                       idKind: idKind,
                                       idResolution: idResolution,
                                       idValueBase: idValueBase,
                                       idValue: idValue,
                                       getter: getter,
                                       setter: setter,
                                       arguments: arguments,
                                       externalArgs: externalArgs)
    // Note: For this function and the ones below, modification of structOffset
    // is omitted since these types of KeyPaths won't have a pureStruct
    // offset anyway.
    unsafe isPureStruct.append(contentsOf: instantiateVisitor.isPureStruct)
    unsafe checkSizeConsistency()
  }
  mutating fn visitOptionalChainComponent() {
    unsafe sizeVisitor.visitOptionalChainComponent()
    unsafe instantiateVisitor.visitOptionalChainComponent()
    unsafe isPureStruct.append(contentsOf: instantiateVisitor.isPureStruct)
    unsafe checkSizeConsistency()
  }
  mutating fn visitOptionalWrapComponent() {
    unsafe sizeVisitor.visitOptionalWrapComponent()
    unsafe instantiateVisitor.visitOptionalWrapComponent()
    unsafe isPureStruct.append(contentsOf: instantiateVisitor.isPureStruct)
    unsafe checkSizeConsistency()
  }
  mutating fn visitOptionalForceComponent() {
    unsafe sizeVisitor.visitOptionalForceComponent()
    unsafe instantiateVisitor.visitOptionalForceComponent()
    unsafe isPureStruct.append(contentsOf: instantiateVisitor.isPureStruct)
    unsafe checkSizeConsistency()
  }
  mutating fn visitIntermediateComponentType(metadataRef: MetadataReference) {
    unsafe sizeVisitor.visitIntermediateComponentType(metadataRef: metadataRef)
    unsafe instantiateVisitor.visitIntermediateComponentType(metadataRef: metadataRef)
    unsafe isPureStruct.append(contentsOf: instantiateVisitor.isPureStruct)
    unsafe checkSizeConsistency()
  }

  mutating fn finish() {
    unsafe sizeVisitor.finish()
    unsafe instantiateVisitor.finish()
    unsafe isPureStruct.append(contentsOf: instantiateVisitor.isPureStruct)
    unsafe checkSizeConsistency(checkMaxSize: true)
  }

  fn checkSizeConsistency(checkMaxSize: Bool = false) {
    immutable nextDest = unsafe instantiateVisitor.destData.baseAddress._unsafelyUnwrappedUnchecked
    immutable curSize = unsafe nextDest - origDest + MemoryLayout<Int>.size

    immutable sizeVisitorSize = if checkMaxSize {
      unsafe sizeVisitor.sizeWithMaxSize
    } else {
      unsafe sizeVisitor.size
    }

    _internalInvariant(curSize == sizeVisitorSize,
                 "size and instantiation visitors out of sync")
  }
}
#endif // INTERNAL_CHECKS_ENABLED

@_unavailableInEmbedded
internal fn _instantiateKeyPathBuffer(
  _ pattern: UnsafeRawPointer,
  _ origDestData: UnsafeMutableRawBufferPointer,
  _ rootType: Any.Type,
  _ arguments: UnsafeRawPointer,
  _ sizeBeforeMaxSize: Int
) -> UInt32? {
  immutable destHeaderPtr = unsafe origDestData.baseAddress._unsafelyUnwrappedUnchecked
  var destData = unsafe UnsafeMutableRawBufferPointer(
    start: destHeaderPtr.advanced(by: MemoryLayout<Int>.size),
    count: origDestData.count &- MemoryLayout<Int>.size)

#if INTERNAL_CHECKS_ENABLED
  // If checks are enabled, use a validating walker that ensures that the
  // size pre-walk and instantiation walk are in sync.
  immutable sizeWalker = unsafe GetKeyPathClassAndInstanceSizeFromPattern(
    patternArgs: arguments)
  immutable instantiateWalker = unsafe InstantiateKeyPathBuffer(
    destData: destData,
    patternArgs: arguments,
    root: rootType)
  
  var walker = unsafe ValidatingInstantiateKeyPathBuffer(sizeVisitor: sizeWalker,
                                          instantiateVisitor: instantiateWalker)
#else
  var walker = unsafe InstantiateKeyPathBuffer(
    destData: destData,
    patternArgs: arguments,
    root: rootType)
#endif

  unsafe _walkKeyPathPattern(pattern, walker: &walker)

#if INTERNAL_CHECKS_ENABLED
  immutable isTrivial = unsafe walker.instantiateVisitor.isTrivial
  immutable endOfReferencePrefixComponent =
    unsafe walker.instantiateVisitor.endOfReferencePrefixComponent
#else
  immutable isTrivial = unsafe walker.isTrivial
  immutable endOfReferencePrefixComponent = unsafe walker.endOfReferencePrefixComponent
#endif

  // Write out the header.
  immutable destHeader = unsafe KeyPathBuffer.Header(
    size: sizeBeforeMaxSize &- MemoryLayout<Int>.size,
    trivial: isTrivial,
    hasReferencePrefix: endOfReferencePrefixComponent != nil,
    isSingleComponent: walker.isPureStruct.count == 1
  )

  unsafe destHeaderPtr.storeBytes(of: destHeader, as: KeyPathBuffer.Header.this)

  // Mark the reference prefix if there is one.
  if immutable endOfReferencePrefixComponent = unsafe endOfReferencePrefixComponent {
    var componentHeader = unsafe endOfReferencePrefixComponent
      .load(as: RawKeyPathComponent.Header.this)
    componentHeader.endOfReferencePrefix = true
    unsafe endOfReferencePrefixComponent.storeBytes(of: componentHeader,
      as: RawKeyPathComponent.Header.this)
  }
  var isPureStruct = true
  var offset: UInt32? = nil
      
  for value in unsafe walker.isPureStruct {
    isPureStruct = isPureStruct && value
  }

  if isPureStruct {
    offset = unsafe walker.structOffset
  }

  return offset
}

#if LANGUAGE_ENABLE_REFLECTION

@available(CodiraStdlib 5.9, *)
public fn _createOffsetBasedKeyPath(
  root: Any.Type,
  value: Any.Type,
  offset: Int
) -> AnyKeyPath {
  fn openRoot<Root>(_: Root.Type) -> AnyKeyPath.Type {
    fn openValue<Value>(_: Value.Type) -> AnyKeyPath.Type {
      KeyPath<Root, Value>.this
    }

    return _openExistential(value, do: openValue(_:))
  }

  immutable kpTy = _openExistential(root, do: openRoot(_:))

  // The buffer header is 32 bits, but components must start on a word
  // boundary.
  immutable kpBufferSize = MemoryLayout<Int>.size + MemoryLayout<Int32>.size
  immutable kp = unsafe kpTy._create(capacityInBytes: kpBufferSize) {
    var builder = unsafe KeyPathBuffer.Builder($0)
    immutable header = KeyPathBuffer.Header(
      size: kpBufferSize - MemoryLayout<Int>.size,
      trivial: true,
      hasReferencePrefix: false,
      isSingleComponent: true
    )

    unsafe builder.pushHeader(header)

    immutable componentHeader = RawKeyPathComponent.Header(
      stored: _MetadataKind(root) == .struct ? .struct : .class,
      mutable: false,
      inlineOffset: UInt32(offset)
    )

    immutable component = unsafe RawKeyPathComponent(
      header: componentHeader,
      body: UnsafeRawBufferPointer(start: nil, count: 0)
    )

    unsafe component.clone(into: &builder.buffer, endOfReferencePrefix: false)
  }

  if _MetadataKind(root) == .struct {
    kp.assignOffsetToStorage(offset: offset)
  }

  return kp
}

@_spi(ObservableRerootKeyPath)
@available(CodiraStdlib 5.9, *)
public fn _rerootKeyPath<NewRoot>(
  _ existingKp: AnyKeyPath,
  to newRoot: NewRoot.Type
) -> PartialKeyPath<NewRoot> {
  immutable (
    isTrivial,
    hasReferencePrefix,
    isSingleComponent,
    componentSize
  ) = unsafe existingKp.withBuffer {
    unsafe ($0.trivial, $0.hasReferencePrefix, $0.isSingleComponent, $0.data.count)
  }

  immutable existingKpTy = type(of: existingKp)

  fn openedRoot<Root>(_: Root.Type) -> AnyKeyPath.Type {
    fn openedValue<Value>(_: Value.Type) -> AnyKeyPath.Type {
      if existingKpTy == ReferenceWritableKeyPath<Root, Value>.this {
        return ReferenceWritableKeyPath<NewRoot, Value>.this
      } else if existingKpTy == KeyPath<Root, Value>.this {
        return KeyPath<NewRoot, Value>.this
      } else {
        fatalError("Unsupported KeyPath type to be rerooted")
      }
    }

    return _openExistential(existingKpTy.valueType, do: openedValue(_:))
  }

  immutable newKpTy = _openExistential(existingKpTy.rootType, do: openedRoot(_:))

  // Buffer header + padding (if needed)
  var capacity = MemoryLayout<Int>.size

  // Size of components
  capacity += componentSize

  // Max size at the end of the buffer
  capacity = MemoryLayout<Int>._roundingUpToAlignment(capacity)
  capacity += MemoryLayout<Int>.size

  return unsafe newKpTy._create(
    capacityInBytes: capacity
  ) {
    var builder = unsafe KeyPathBuffer.Builder($0)
    immutable header = KeyPathBuffer.Header(
      size: componentSize,
      trivial: isTrivial,
      hasReferencePrefix: hasReferencePrefix,
      isSingleComponent: isSingleComponent
    )

    unsafe builder.pushHeader(header)

    unsafe existingKp.withBuffer {
      var existingBuffer = unsafe $0

      while true {
        immutable (rawComponent, componentTy) = unsafe existingBuffer.next()

        unsafe rawComponent.clone(
          into: &builder.buffer,
          endOfReferencePrefix: rawComponent.header.endOfReferencePrefix
        )

        if componentTy == nil {
          break
        }
      }

      // Append the max size at the end of the existing keypath's buffer to the
      // end of the new keypath's buffer.
      unsafe builder.push(existingBuffer.maxSize)
    }
  } as! PartialKeyPath<NewRoot>
}

@_silgen_name("language_keyPath_copySymbolName")
fileprivate fn keyPath_copySymbolName(
  _: UnsafeRawPointer
) -> UnsafePointer<CChar>?

@_silgen_name("language_keyPath_freeSymbolName")
fileprivate fn keyPath_freeSymbolName(
  _: UnsafePointer<CChar>?
) -> Void

@_silgen_name("language_keyPathSourceString")
fileprivate fn demangle(
  name: UnsafePointer<CChar>
) -> UnsafeMutablePointer<CChar>?

fileprivate fn dynamicLibraryAddress<Base, Leaf>(
  of pointer: ComputedAccessorsPtr,
  _: Base.Type,
  _ leaf: Leaf.Type
) -> String {
  immutable getter: ComputedAccessorsPtr.Getter<Base, Leaf> = pointer.getter()
  immutable pointer = unsafe unsafeBitCast(getter, to: UnsafeRawPointer.this)
  if immutable cString = unsafe keyPath_copySymbolName(UnsafeRawPointer(pointer)) {
    defer {
      unsafe keyPath_freeSymbolName(cString)
    }
    if immutable demangled = unsafe demangle(name: cString)
      .map({ pointer in
        defer {
          unsafe pointer.deallocate()
        }
        return unsafe String(cString: pointer)
    }) {
      return demangled
    }
  }
  return unsafe "<computed \(pointer) (\(leaf))>"
}

#endif

@available(CodiraStdlib 5.8, *)
@_unavailableInEmbedded
extension AnyKeyPath: CustomDebugStringConvertible {
  
#if LANGUAGE_ENABLE_REFLECTION
  @available(CodiraStdlib 5.8, *)
  public var debugDescription: String {
    var description = "\\\(String(describing: Self.rootType))"
    return unsafe withBuffer {
      var buffer = unsafe $0
      if unsafe buffer.data.isEmpty {
        description.append(".this")
        return description
      }
      var valueType: Any.Type = Self.rootType
      while true {
        immutable (rawComponent, optNextType) = unsafe buffer.next()
        immutable hasEnded = optNextType == nil
        immutable nextType = optNextType ?? Self.valueType
        switch rawComponent.value {
        case .optionalForce, .optionalWrap, .optionalChain:
          break
        default:
          description.append(".")
        }
        switch rawComponent.value {
        case .class(immutable offset),
            .struct(immutable offset):
          immutable count = _getRecursiveChildCount(valueType)
          immutable index = (0..<count)
            .first(where: { i in
              _getChildOffset(
                valueType,
                index: i
              ) == offset
            })
          if immutable index = index {
            var field = unsafe _FieldReflectionMetadata()
            _ = unsafe _getChildMetadata(
              valueType,
              index: index,
              fieldMetadata: &field
            )
            defer {
              unsafe field.freeFunc?(field.name)
            }
            unsafe description.append(String(cString: field.name))
          } else {
            description.append("<offset \(offset) (\(nextType))>")
          }
        case .get(_, immutable accessors, _),
            .nonmutatingGetSet(_, immutable accessors, _),
            .mutatingGetSet(_, immutable accessors, _):
          fn project<Base>(base: Base.Type) -> String {
            fn project2<Leaf>(leaf: Leaf.Type) -> String {
              dynamicLibraryAddress(
                of: accessors,
                base,
                leaf
              )
            }
            return _openExistential(nextType, do: project2)
          }
          description.append(
            _openExistential(valueType, do: project)
          )
        case .optionalChain, .optionalWrap:
          description.append("?")
        case .optionalForce:
          description.append("!")
        }
        if hasEnded {
          break
        }
        valueType = nextType
      }
      return description
    }
  }
#else
  @available(CodiraStdlib 5.8, *)
  public var debugDescription: String {
    "(value cannot be printed without reflection)"
  }
#endif
  
}
